{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":56377,"status":"ok","timestamp":1704520639997,"user":{"displayName":"Weiming Li","userId":"10689989110268100587"},"user_tz":-480},"id":"CR24_cEGvQP3"},"outputs":[],"source":["%%capture\n","%%bash\n","# Install ViZDoom deps from\n","# https://github.com/mwydmuch/ViZDoom/blob/master/doc/Building.md#-linux\n","\n","apt-get install build-essential zlib1g-dev libsdl2-dev libjpeg-dev \\\n","nasm tar libbz2-dev libgtk2.0-dev cmake git libfluidsynth-dev libgme-dev \\\n","libopenal-dev timidity libwildmidi-dev unzip ffmpeg\n","\n","# Boost libraries\n","apt-get install libboost-all-dev\n","\n","# Lua binding dependencies\n","apt-get install liblua5.1-dev"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31610,"status":"ok","timestamp":1704520697505,"user":{"displayName":"Weiming Li","userId":"10689989110268100587"},"user_tz":-480},"id":"002gzK8gTUNI","outputId":"8bab06dc-1f6b-406a-ce2b-418f49a8f5ad"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting faster-fifo==1.4.2\n","  Downloading faster-fifo-1.4.2.tar.gz (84 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.6/84.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: setuptools\u003e=45.2.0 in /usr/local/lib/python3.10/dist-packages (from faster-fifo==1.4.2) (67.7.2)\n","Requirement already satisfied: cython\u003e=0.29 in /usr/local/lib/python3.10/dist-packages (from faster-fifo==1.4.2) (3.0.7)\n","Building wheels for collected packages: faster-fifo\n","  Building wheel for faster-fifo (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for faster-fifo: filename=faster_fifo-1.4.2-cp310-cp310-linux_x86_64.whl size=333548 sha256=6bfa3eff0f9c2a049fc44c55e1d5f7e974d89856b93d6a4c66ca4dd82f1ed760\n","  Stored in directory: /root/.cache/pip/wheels/e9/72/37/2c9091826a1ceb1e7ece278f0e074e80be349a05fdb0a53d0d\n","Successfully built faster-fifo\n","Installing collected packages: faster-fifo\n","Successfully installed faster-fifo-1.4.2\n","Collecting vizdoom\n","  Downloading vizdoom-1.2.3-cp310-cp310-manylinux_2_28_x86_64.whl (28.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.0/28.0 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from vizdoom) (1.23.5)\n","Collecting gymnasium\u003e=0.28.0 (from vizdoom)\n","  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pygame\u003e=2.1.3 in /usr/local/lib/python3.10/dist-packages (from vizdoom) (2.5.2)\n","Requirement already satisfied: cloudpickle\u003e=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium\u003e=0.28.0-\u003evizdoom) (2.2.1)\n","Requirement already satisfied: typing-extensions\u003e=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium\u003e=0.28.0-\u003evizdoom) (4.5.0)\n","Collecting farama-notifications\u003e=0.0.1 (from gymnasium\u003e=0.28.0-\u003evizdoom)\n","  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n","Installing collected packages: farama-notifications, gymnasium, vizdoom\n","Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1 vizdoom-1.2.3\n"]}],"source":["# install python libraries\n","# thanks toinsson\n","!pip install faster-fifo==1.4.2\n","!pip install vizdoom"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8819,"status":"ok","timestamp":1704520882488,"user":{"displayName":"Weiming Li","userId":"10689989110268100587"},"user_tz":-480},"id":"gjspUnChTV23","outputId":"1f0debd5-9735-465f-a851-0654ac5d9707"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: sample-factory==2.0.2 in /usr/local/lib/python3.10/dist-packages (2.0.2)\n","Requirement already satisfied: numpy\u003e=1.18.1\u003c2.0 in /usr/local/lib/python3.10/dist-packages (from sample-factory==2.0.2) (1.23.5)\n","Requirement already satisfied: torch\u003c2.0,\u003e=1.9 in /usr/local/lib/python3.10/dist-packages (from sample-factory==2.0.2) (1.13.1)\n","Requirement already satisfied: gym\u003c1.0,\u003e=0.26.1 in /usr/local/lib/python3.10/dist-packages (from sample-factory==2.0.2) (0.26.2)\n","Requirement already satisfied: pyglet in /usr/local/lib/python3.10/dist-packages (from sample-factory==2.0.2) (2.0.10)\n","Requirement already satisfied: tensorboard\u003e=1.15.0 in /usr/local/lib/python3.10/dist-packages (from sample-factory==2.0.2) (2.15.1)\n","Requirement already satisfied: tensorboardx\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from sample-factory==2.0.2) (2.6.2.2)\n","Requirement already satisfied: psutil\u003e=5.7.0 in /usr/local/lib/python3.10/dist-packages (from sample-factory==2.0.2) (5.9.5)\n","Requirement already satisfied: threadpoolctl\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sample-factory==2.0.2) (3.2.0)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from sample-factory==2.0.2) (6.8.0)\n","Requirement already satisfied: faster-fifo\u003c2.0,\u003e=1.4.2 in /usr/local/lib/python3.10/dist-packages (from sample-factory==2.0.2) (1.4.5)\n","Requirement already satisfied: signal-slot-mp\u003c2.0,\u003e=1.0.3 in /usr/local/lib/python3.10/dist-packages (from sample-factory==2.0.2) (1.0.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from sample-factory==2.0.2) (3.13.1)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from sample-factory==2.0.2) (4.8.0.76)\n","Requirement already satisfied: wandb\u003e=0.12.9 in /usr/local/lib/python3.10/dist-packages (from sample-factory==2.0.2) (0.16.1)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.10.0 in /usr/local/lib/python3.10/dist-packages (from sample-factory==2.0.2) (0.20.1)\n","Requirement already satisfied: setuptools\u003e=45.2.0 in /usr/local/lib/python3.10/dist-packages (from faster-fifo\u003c2.0,\u003e=1.4.2-\u003esample-factory==2.0.2) (67.7.2)\n","Requirement already satisfied: cython\u003e=0.29 in /usr/local/lib/python3.10/dist-packages (from faster-fifo\u003c2.0,\u003e=1.4.2-\u003esample-factory==2.0.2) (3.0.7)\n","Requirement already satisfied: cloudpickle\u003e=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym\u003c1.0,\u003e=0.26.1-\u003esample-factory==2.0.2) (2.2.1)\n","Requirement already satisfied: gym-notices\u003e=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym\u003c1.0,\u003e=0.26.1-\u003esample-factory==2.0.2) (0.0.8)\n","Requirement already satisfied: fsspec\u003e=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.10.0-\u003esample-factory==2.0.2) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.10.0-\u003esample-factory==2.0.2) (2.31.0)\n","Requirement already satisfied: tqdm\u003e=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.10.0-\u003esample-factory==2.0.2) (4.66.1)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.10.0-\u003esample-factory==2.0.2) (6.0.1)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.10.0-\u003esample-factory==2.0.2) (4.5.0)\n","Requirement already satisfied: packaging\u003e=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.10.0-\u003esample-factory==2.0.2) (23.2)\n","Requirement already satisfied: absl-py\u003e=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003e=1.15.0-\u003esample-factory==2.0.2) (1.4.0)\n","Requirement already satisfied: grpcio\u003e=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003e=1.15.0-\u003esample-factory==2.0.2) (1.60.0)\n","Requirement already satisfied: google-auth\u003c3,\u003e=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003e=1.15.0-\u003esample-factory==2.0.2) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib\u003c2,\u003e=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003e=1.15.0-\u003esample-factory==2.0.2) (1.2.0)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003e=1.15.0-\u003esample-factory==2.0.2) (3.5.1)\n","Requirement already satisfied: protobuf\u003c4.24,\u003e=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003e=1.15.0-\u003esample-factory==2.0.2) (3.20.3)\n","Requirement already satisfied: six\u003e1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003e=1.15.0-\u003esample-factory==2.0.2) (1.16.0)\n","Requirement already satisfied: tensorboard-data-server\u003c0.8.0,\u003e=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003e=1.15.0-\u003esample-factory==2.0.2) (0.7.2)\n","Requirement already satisfied: werkzeug\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003e=1.15.0-\u003esample-factory==2.0.2) (3.0.1)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch\u003c2.0,\u003e=1.9-\u003esample-factory==2.0.2) (11.7.99)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch\u003c2.0,\u003e=1.9-\u003esample-factory==2.0.2) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch\u003c2.0,\u003e=1.9-\u003esample-factory==2.0.2) (11.10.3.66)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch\u003c2.0,\u003e=1.9-\u003esample-factory==2.0.2) (11.7.99)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66-\u003etorch\u003c2.0,\u003e=1.9-\u003esample-factory==2.0.2) (0.42.0)\n","Requirement already satisfied: Click!=8.0.0,\u003e=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb\u003e=0.12.9-\u003esample-factory==2.0.2) (8.1.7)\n","Requirement already satisfied: GitPython!=3.1.29,\u003e=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb\u003e=0.12.9-\u003esample-factory==2.0.2) (3.1.40)\n","Requirement already satisfied: sentry-sdk\u003e=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb\u003e=0.12.9-\u003esample-factory==2.0.2) (1.39.1)\n","Requirement already satisfied: docker-pycreds\u003e=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb\u003e=0.12.9-\u003esample-factory==2.0.2) (0.4.0)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb\u003e=0.12.9-\u003esample-factory==2.0.2) (1.3.3)\n","Requirement already satisfied: appdirs\u003e=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb\u003e=0.12.9-\u003esample-factory==2.0.2) (1.4.4)\n","Requirement already satisfied: gitdb\u003c5,\u003e=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,\u003e=1.0.0-\u003ewandb\u003e=0.12.9-\u003esample-factory==2.0.2) (4.0.11)\n","Requirement already satisfied: cachetools\u003c6.0,\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003e=1.15.0-\u003esample-factory==2.0.2) (5.3.2)\n","Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003e=1.15.0-\u003esample-factory==2.0.2) (0.3.0)\n","Requirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003e=1.15.0-\u003esample-factory==2.0.2) (4.9)\n","Requirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib\u003c2,\u003e=0.5-\u003etensorboard\u003e=1.15.0-\u003esample-factory==2.0.2) (1.3.1)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub\u003c1.0,\u003e=0.10.0-\u003esample-factory==2.0.2) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub\u003c1.0,\u003e=0.10.0-\u003esample-factory==2.0.2) (3.6)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub\u003c1.0,\u003e=0.10.0-\u003esample-factory==2.0.2) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub\u003c1.0,\u003e=0.10.0-\u003esample-factory==2.0.2) (2023.11.17)\n","Requirement already satisfied: MarkupSafe\u003e=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug\u003e=1.0.1-\u003etensorboard\u003e=1.15.0-\u003esample-factory==2.0.2) (2.1.3)\n","Requirement already satisfied: smmap\u003c6,\u003e=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb\u003c5,\u003e=4.0.1-\u003eGitPython!=3.1.29,\u003e=1.0.0-\u003ewandb\u003e=0.12.9-\u003esample-factory==2.0.2) (5.0.1)\n","Requirement already satisfied: pyasn1\u003c0.6.0,\u003e=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003e=1.15.0-\u003esample-factory==2.0.2) (0.5.1)\n","Requirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u003c2,\u003e=0.5-\u003etensorboard\u003e=1.15.0-\u003esample-factory==2.0.2) (3.2.2)\n"]}],"source":["!pip install sample-factory==2.0.2"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3075,"status":"ok","timestamp":1704520927757,"user":{"displayName":"Weiming Li","userId":"10689989110268100587"},"user_tz":-480},"id":"gnzhbZRiTekc"},"outputs":[],"source":["import functools\n","\n","from sample_factory.algo.utils.context import global_model_factory\n","from sample_factory.cfg.arguments import parse_full_cfg, parse_sf_args\n","from sample_factory.envs.env_utils import register_env\n","from sample_factory.train import run_rl\n","\n","from sf_examples.vizdoom.doom.doom_model import make_vizdoom_encoder\n","from sf_examples.vizdoom.doom.doom_params import add_doom_env_args, doom_override_defaults\n","from sf_examples.vizdoom.doom.doom_utils import DOOM_ENVS, make_doom_env_from_spec\n","\n","\n","# Registers all the ViZDoom environments\n","def register_vizdoom_envs():\n","    for env_spec in DOOM_ENVS:\n","        make_env_func = functools.partial(make_doom_env_from_spec, env_spec)\n","        register_env(env_spec.name, make_env_func)\n","\n","# Sample Factory allows the registration of a custom Neural Network architecture\n","# See https://github.com/alex-petrenko/sample-factory/blob/master/sf_examples/vizdoom/doom/doom_model.py for more details\n","def register_vizdoom_models():\n","    global_model_factory().register_encoder_factory(make_vizdoom_encoder)\n","\n","\n","def register_vizdoom_components():\n","    register_vizdoom_envs()\n","    register_vizdoom_models()\n","\n","# parse the command line args and create a config\n","def parse_vizdoom_cfg(argv=None, evaluation=False):\n","    parser, _ = parse_sf_args(argv=argv, evaluation=evaluation)\n","    # parameters specific to Doom envs\n","    add_doom_env_args(parser)\n","    # override Doom default values for algo parameters\n","    doom_override_defaults(parser)\n","    # second parsing pass yields the final configuration\n","    final_cfg = parse_full_cfg(parser, argv)\n","    return final_cfg"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1679802,"status":"ok","timestamp":1704522644351,"user":{"displayName":"Weiming Li","userId":"10689989110268100587"},"user_tz":-480},"id":"7eojvsefTfN_","outputId":"9b812c16-a646-4fb8-f72f-5e8c74996e44"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[36m[2024-01-06 06:02:44,264][00204] register_encoder_factory: \u003cfunction make_vizdoom_encoder at 0x7a26467b4670\u003e\u001b[0m\n","\u001b[33m[2024-01-06 06:02:44,276][00204] Saved parameter configuration for experiment default_experiment not found!\u001b[0m\n","\u001b[33m[2024-01-06 06:02:44,277][00204] Starting experiment from scratch!\u001b[0m\n","\u001b[36m[2024-01-06 06:02:44,293][00204] Experiment dir /content/train_dir/default_experiment already exists!\u001b[0m\n","\u001b[36m[2024-01-06 06:02:44,294][00204] Resuming existing experiment from /content/train_dir/default_experiment...\u001b[0m\n","\u001b[36m[2024-01-06 06:02:44,297][00204] Weights and Biases integration disabled\u001b[0m\n","\u001b[36m[2024-01-06 06:02:46,746][00204] Queried available GPUs: 0\n","\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:02:46,748][00204] Environment var CUDA_VISIBLE_DEVICES is 0\n","\u001b[0m\n","\u001b[36m[2024-01-06 06:02:48,380][00204] Starting experiment with the following configuration:\n","help=False\n","algo=APPO\n","env=doom_health_gathering_supreme\n","experiment=default_experiment\n","train_dir=/content/train_dir\n","restart_behavior=resume\n","device=gpu\n","seed=None\n","num_policies=1\n","async_rl=True\n","serial_mode=False\n","batched_sampling=False\n","num_batches_to_accumulate=2\n","worker_num_splits=2\n","policy_workers_per_policy=1\n","max_policy_lag=1000\n","num_workers=8\n","num_envs_per_worker=4\n","batch_size=1024\n","num_batches_per_epoch=1\n","num_epochs=1\n","rollout=32\n","recurrence=32\n","shuffle_minibatches=False\n","gamma=0.99\n","reward_scale=1.0\n","reward_clip=1000.0\n","value_bootstrap=False\n","normalize_returns=True\n","exploration_loss_coeff=0.001\n","value_loss_coeff=0.5\n","kl_loss_coeff=0.0\n","exploration_loss=symmetric_kl\n","gae_lambda=0.95\n","ppo_clip_ratio=0.1\n","ppo_clip_value=0.2\n","with_vtrace=False\n","vtrace_rho=1.0\n","vtrace_c=1.0\n","optimizer=adam\n","adam_eps=1e-06\n","adam_beta1=0.9\n","adam_beta2=0.999\n","max_grad_norm=4.0\n","learning_rate=0.0001\n","lr_schedule=constant\n","lr_schedule_kl_threshold=0.008\n","obs_subtract_mean=0.0\n","obs_scale=255.0\n","normalize_input=True\n","normalize_input_keys=None\n","decorrelate_experience_max_seconds=0\n","decorrelate_envs_on_one_worker=True\n","actor_worker_gpus=[]\n","set_workers_cpu_affinity=True\n","force_envs_single_thread=False\n","default_niceness=0\n","log_to_file=True\n","experiment_summaries_interval=10\n","flush_summaries_interval=30\n","stats_avg=100\n","summaries_use_frameskip=True\n","heartbeat_interval=20\n","heartbeat_reporting_interval=600\n","train_for_env_steps=5000000\n","train_for_seconds=10000000000\n","save_every_sec=120\n","keep_checkpoints=2\n","load_checkpoint_kind=latest\n","save_milestones_sec=-1\n","save_best_every_sec=5\n","save_best_metric=reward\n","save_best_after=100000\n","benchmark=False\n","encoder_mlp_layers=[512, 512]\n","encoder_conv_architecture=convnet_simple\n","encoder_conv_mlp_layers=[512]\n","use_rnn=True\n","rnn_size=512\n","rnn_type=gru\n","rnn_num_layers=1\n","decoder_mlp_layers=[]\n","nonlinearity=elu\n","policy_initialization=orthogonal\n","policy_init_gain=1.0\n","actor_critic_share_weights=True\n","adaptive_stddev=True\n","continuous_tanh_scale=0.0\n","initial_stddev=1.0\n","use_env_info_cache=False\n","env_gpu_actions=False\n","env_gpu_observations=True\n","env_frameskip=4\n","env_framestack=1\n","pixel_format=CHW\n","use_record_episode_statistics=False\n","with_wandb=False\n","wandb_user=None\n","wandb_project=sample_factory\n","wandb_group=None\n","wandb_job_type=SF\n","wandb_tags=[]\n","with_pbt=False\n","pbt_mix_policies_in_one_env=True\n","pbt_period_env_steps=5000000\n","pbt_start_mutation=20000000\n","pbt_replace_fraction=0.3\n","pbt_mutation_rate=0.15\n","pbt_replace_reward_gap=0.1\n","pbt_replace_reward_gap_absolute=1e-06\n","pbt_optimize_gamma=False\n","pbt_target_objective=true_objective\n","pbt_perturb_min=1.1\n","pbt_perturb_max=1.5\n","num_agents=-1\n","num_humans=0\n","num_bots=-1\n","start_bot_difficulty=None\n","timelimit=None\n","res_w=128\n","res_h=72\n","wide_aspect_ratio=False\n","eval_env_frameskip=1\n","fps=35\n","command_line=--env=doom_health_gathering_supreme --num_workers=8 --num_envs_per_worker=4 --train_for_env_steps=5000000\n","cli_args={'env': 'doom_health_gathering_supreme', 'num_workers': 8, 'num_envs_per_worker': 4, 'train_for_env_steps': 5000000}\n","git_hash=unknown\n","git_repo_name=not a git repository\n","train_script=.usr.local.lib.python3.10.dist-packages.colab_kernel_launcher\u001b[0m\n","\u001b[36m[2024-01-06 06:02:48,383][00204] Saving configuration to /content/train_dir/default_experiment/config.json...\u001b[0m\n","\u001b[36m[2024-01-06 06:02:48,386][00204] Rollout worker 0 uses device cpu\u001b[0m\n","\u001b[36m[2024-01-06 06:02:48,388][00204] Rollout worker 1 uses device cpu\u001b[0m\n","\u001b[36m[2024-01-06 06:02:48,389][00204] Rollout worker 2 uses device cpu\u001b[0m\n","\u001b[36m[2024-01-06 06:02:48,391][00204] Rollout worker 3 uses device cpu\u001b[0m\n","\u001b[36m[2024-01-06 06:02:48,392][00204] Rollout worker 4 uses device cpu\u001b[0m\n","\u001b[36m[2024-01-06 06:02:48,393][00204] Rollout worker 5 uses device cpu\u001b[0m\n","\u001b[36m[2024-01-06 06:02:48,394][00204] Rollout worker 6 uses device cpu\u001b[0m\n","\u001b[36m[2024-01-06 06:02:48,396][00204] Rollout worker 7 uses device cpu\u001b[0m\n","\u001b[36m[2024-01-06 06:02:48,549][00204] Using GPUs [0] for process 0 (actually maps to GPUs [0])\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:02:48,550][00204] InferenceWorker_p0-w0: min num requests: 2\u001b[0m\n","\u001b[36m[2024-01-06 06:02:48,585][00204] Starting all processes...\u001b[0m\n","\u001b[36m[2024-01-06 06:02:48,587][00204] Starting process learner_proc0\u001b[0m\n","\u001b[36m[2024-01-06 06:02:48,643][00204] Starting all processes...\u001b[0m\n","\u001b[36m[2024-01-06 06:02:48,655][00204] Starting process inference_proc0-0\u001b[0m\n","\u001b[36m[2024-01-06 06:02:48,655][00204] Starting process rollout_proc0\u001b[0m\n","\u001b[36m[2024-01-06 06:02:48,657][00204] Starting process rollout_proc1\u001b[0m\n","\u001b[36m[2024-01-06 06:02:48,657][00204] Starting process rollout_proc2\u001b[0m\n","\u001b[36m[2024-01-06 06:02:48,657][00204] Starting process rollout_proc3\u001b[0m\n","\u001b[36m[2024-01-06 06:02:48,657][00204] Starting process rollout_proc4\u001b[0m\n","\u001b[36m[2024-01-06 06:02:48,657][00204] Starting process rollout_proc5\u001b[0m\n","\u001b[36m[2024-01-06 06:02:48,657][00204] Starting process rollout_proc6\u001b[0m\n","\u001b[36m[2024-01-06 06:02:48,657][00204] Starting process rollout_proc7\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:03:08,374][00204] Inference worker 0-0 is ready!\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:03:08,376][00204] All inference workers are ready! Signal rollout workers to start!\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:03:08,540][00204] Heartbeat connected on Batcher_0\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:03:08,546][00204] Heartbeat connected on LearnerWorker_p0\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:03:08,588][00204] Heartbeat connected on InferenceWorker_p0-w0\u001b[0m\n","\u001b[36m[2024-01-06 06:03:09,304][00204] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 0. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:03:13,801][00204] Heartbeat connected on RolloutWorker_w5\u001b[0m\n","\u001b[36m[2024-01-06 06:03:14,307][00204] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:03:15,861][00204] Heartbeat connected on RolloutWorker_w6\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:03:18,161][00204] Heartbeat connected on RolloutWorker_w7\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:03:19,082][00204] Heartbeat connected on RolloutWorker_w2\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:03:19,297][00204] Heartbeat connected on RolloutWorker_w0\u001b[0m\n","\u001b[36m[2024-01-06 06:03:19,304][00204] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1.6. Samples: 16. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:03:19,312][00204] Avg episode reward: [(0, '1.280')]\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:03:23,536][00204] Heartbeat connected on RolloutWorker_w4\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:03:23,676][00204] Heartbeat connected on RolloutWorker_w3\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:03:23,841][00204] Heartbeat connected on RolloutWorker_w1\u001b[0m\n","\u001b[36m[2024-01-06 06:03:24,304][00204] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 134.8. Samples: 2022. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:03:24,307][00204] Avg episode reward: [(0, '3.376')]\u001b[0m\n","\u001b[36m[2024-01-06 06:03:29,304][00204] Fps is (10 sec: 1638.4, 60 sec: 819.2, 300 sec: 819.2). Total num frames: 16384. Throughput: 0: 149.8. Samples: 2996. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:03:29,312][00204] Avg episode reward: [(0, '3.589')]\u001b[0m\n","\u001b[36m[2024-01-06 06:03:34,304][00204] Fps is (10 sec: 3276.8, 60 sec: 1310.7, 300 sec: 1310.7). Total num frames: 32768. Throughput: 0: 328.7. Samples: 8218. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:03:34,307][00204] Avg episode reward: [(0, '3.993')]\u001b[0m\n","\u001b[36m[2024-01-06 06:03:39,304][00204] Fps is (10 sec: 2867.1, 60 sec: 1501.9, 300 sec: 1501.9). Total num frames: 45056. Throughput: 0: 393.7. Samples: 11810. Policy #0 lag: (min: 0.0, avg: 0.4, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:03:39,308][00204] Avg episode reward: [(0, '4.262')]\u001b[0m\n","\u001b[36m[2024-01-06 06:03:44,306][00204] Fps is (10 sec: 2457.2, 60 sec: 1638.3, 300 sec: 1638.3). Total num frames: 57344. Throughput: 0: 388.9. Samples: 13612. Policy #0 lag: (min: 0.0, avg: 0.6, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:03:44,308][00204] Avg episode reward: [(0, '4.643')]\u001b[0m\n","\u001b[36m[2024-01-06 06:03:49,304][00204] Fps is (10 sec: 2867.3, 60 sec: 1843.2, 300 sec: 1843.2). Total num frames: 73728. Throughput: 0: 454.8. Samples: 18194. Policy #0 lag: (min: 0.0, avg: 0.6, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:03:49,316][00204] Avg episode reward: [(0, '4.556')]\u001b[0m\n","\u001b[36m[2024-01-06 06:03:54,304][00204] Fps is (10 sec: 3687.0, 60 sec: 2093.5, 300 sec: 2093.5). Total num frames: 94208. Throughput: 0: 529.4. Samples: 23822. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:03:54,306][00204] Avg episode reward: [(0, '4.506')]\u001b[0m\n","\u001b[36m[2024-01-06 06:03:59,304][00204] Fps is (10 sec: 3276.8, 60 sec: 2129.9, 300 sec: 2129.9). Total num frames: 106496. Throughput: 0: 571.9. Samples: 25734. Policy #0 lag: (min: 0.0, avg: 0.6, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:03:59,313][00204] Avg episode reward: [(0, '4.457')]\u001b[0m\n","\u001b[36m[2024-01-06 06:04:04,308][00204] Fps is (10 sec: 2456.6, 60 sec: 2159.5, 300 sec: 2159.5). Total num frames: 118784. Throughput: 0: 650.7. Samples: 29298. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:04:04,316][00204] Avg episode reward: [(0, '4.423')]\u001b[0m\n","\u001b[36m[2024-01-06 06:04:09,304][00204] Fps is (10 sec: 2867.2, 60 sec: 2252.8, 300 sec: 2252.8). Total num frames: 135168. Throughput: 0: 712.6. Samples: 34088. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:04:09,307][00204] Avg episode reward: [(0, '4.276')]\u001b[0m\n","\u001b[36m[2024-01-06 06:04:14,304][00204] Fps is (10 sec: 3687.9, 60 sec: 2594.3, 300 sec: 2394.6). Total num frames: 155648. Throughput: 0: 754.3. Samples: 36938. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:04:14,307][00204] Avg episode reward: [(0, '4.258')]\u001b[0m\n","\u001b[36m[2024-01-06 06:04:19,305][00204] Fps is (10 sec: 3276.6, 60 sec: 2798.9, 300 sec: 2399.1). Total num frames: 167936. Throughput: 0: 747.1. Samples: 41836. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:04:19,316][00204] Avg episode reward: [(0, '4.349')]\u001b[0m\n","\u001b[36m[2024-01-06 06:04:24,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3003.7, 300 sec: 2403.0). Total num frames: 180224. Throughput: 0: 749.2. Samples: 45522. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:04:24,307][00204] Avg episode reward: [(0, '4.447')]\u001b[0m\n","\u001b[36m[2024-01-06 06:04:29,304][00204] Fps is (10 sec: 2867.4, 60 sec: 3003.7, 300 sec: 2457.6). Total num frames: 196608. Throughput: 0: 741.9. Samples: 46998. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:04:29,312][00204] Avg episode reward: [(0, '4.399')]\u001b[0m\n","\u001b[36m[2024-01-06 06:04:34,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3003.7, 300 sec: 2505.8). Total num frames: 212992. Throughput: 0: 768.5. Samples: 52776. Policy #0 lag: (min: 0.0, avg: 0.4, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:04:34,307][00204] Avg episode reward: [(0, '4.268')]\u001b[0m\n","\u001b[36m[2024-01-06 06:04:39,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3072.0, 300 sec: 2548.6). Total num frames: 229376. Throughput: 0: 749.8. Samples: 57564. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:04:39,309][00204] Avg episode reward: [(0, '4.253')]\u001b[0m\n","\u001b[36m[2024-01-06 06:04:44,309][00204] Fps is (10 sec: 2456.4, 60 sec: 3003.6, 300 sec: 2500.6). Total num frames: 237568. Throughput: 0: 728.0. Samples: 58496. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:04:44,313][00204] Avg episode reward: [(0, '4.407')]\u001b[0m\n","\u001b[36m[2024-01-06 06:04:49,309][00204] Fps is (10 sec: 2047.1, 60 sec: 2935.2, 300 sec: 2498.4). Total num frames: 249856. Throughput: 0: 724.7. Samples: 61910. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:04:49,312][00204] Avg episode reward: [(0, '4.617')]\u001b[0m\n","\u001b[36m[2024-01-06 06:04:54,304][00204] Fps is (10 sec: 2868.6, 60 sec: 2867.2, 300 sec: 2535.6). Total num frames: 266240. Throughput: 0: 730.5. Samples: 66960. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:04:54,314][00204] Avg episode reward: [(0, '4.792')]\u001b[0m\n","\u001b[36m[2024-01-06 06:04:59,309][00204] Fps is (10 sec: 3276.8, 60 sec: 2935.2, 300 sec: 2569.2). Total num frames: 282624. Throughput: 0: 727.6. Samples: 69682. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:04:59,311][00204] Avg episode reward: [(0, '4.799')]\u001b[0m\n","\u001b[36m[2024-01-06 06:05:04,304][00204] Fps is (10 sec: 2867.2, 60 sec: 2935.7, 300 sec: 2564.5). Total num frames: 294912. Throughput: 0: 703.3. Samples: 73486. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:05:04,306][00204] Avg episode reward: [(0, '4.838')]\u001b[0m\n","\u001b[36m[2024-01-06 06:05:09,305][00204] Fps is (10 sec: 2458.6, 60 sec: 2867.2, 300 sec: 2560.0). Total num frames: 307200. Throughput: 0: 702.4. Samples: 77132. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:05:09,307][00204] Avg episode reward: [(0, '4.721')]\u001b[0m\n","\u001b[36m[2024-01-06 06:05:14,304][00204] Fps is (10 sec: 3276.8, 60 sec: 2867.2, 300 sec: 2621.4). Total num frames: 327680. Throughput: 0: 733.2. Samples: 79990. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:05:14,306][00204] Avg episode reward: [(0, '4.439')]\u001b[0m\n","\u001b[36m[2024-01-06 06:05:19,304][00204] Fps is (10 sec: 3277.0, 60 sec: 2867.2, 300 sec: 2615.1). Total num frames: 339968. Throughput: 0: 729.5. Samples: 85602. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:05:19,307][00204] Avg episode reward: [(0, '4.358')]\u001b[0m\n","\u001b[36m[2024-01-06 06:05:24,304][00204] Fps is (10 sec: 2457.6, 60 sec: 2867.2, 300 sec: 2609.3). Total num frames: 352256. Throughput: 0: 690.3. Samples: 88626. Policy #0 lag: (min: 0.0, avg: 0.6, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:05:24,307][00204] Avg episode reward: [(0, '4.367')]\u001b[0m\n","\u001b[36m[2024-01-06 06:05:29,304][00204] Fps is (10 sec: 2048.0, 60 sec: 2730.7, 300 sec: 2574.6). Total num frames: 360448. Throughput: 0: 692.5. Samples: 89656. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:05:29,309][00204] Avg episode reward: [(0, '4.292')]\u001b[0m\n","\u001b[36m[2024-01-06 06:05:34,304][00204] Fps is (10 sec: 2457.6, 60 sec: 2730.7, 300 sec: 2598.8). Total num frames: 376832. Throughput: 0: 708.8. Samples: 93802. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:05:34,313][00204] Avg episode reward: [(0, '4.499')]\u001b[0m\n","\u001b[36m[2024-01-06 06:05:39,306][00204] Fps is (10 sec: 3685.8, 60 sec: 2798.9, 300 sec: 2648.7). Total num frames: 397312. Throughput: 0: 724.8. Samples: 99576. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:05:39,314][00204] Avg episode reward: [(0, '4.784')]\u001b[0m\n","\u001b[36m[2024-01-06 06:05:44,304][00204] Fps is (10 sec: 3276.8, 60 sec: 2867.4, 300 sec: 2642.6). Total num frames: 409600. Throughput: 0: 711.9. Samples: 101714. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:05:44,306][00204] Avg episode reward: [(0, '4.699')]\u001b[0m\n","\u001b[36m[2024-01-06 06:05:49,306][00204] Fps is (10 sec: 2457.6, 60 sec: 2867.3, 300 sec: 2636.8). Total num frames: 421888. Throughput: 0: 710.6. Samples: 105466. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:05:49,314][00204] Avg episode reward: [(0, '4.665')]\u001b[0m\n","\u001b[36m[2024-01-06 06:05:54,304][00204] Fps is (10 sec: 2867.2, 60 sec: 2867.2, 300 sec: 2656.2). Total num frames: 438272. Throughput: 0: 731.5. Samples: 110050. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:05:54,307][00204] Avg episode reward: [(0, '4.759')]\u001b[0m\n","\u001b[36m[2024-01-06 06:05:59,304][00204] Fps is (10 sec: 3686.9, 60 sec: 2935.7, 300 sec: 2698.5). Total num frames: 458752. Throughput: 0: 732.5. Samples: 112954. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:05:59,307][00204] Avg episode reward: [(0, '4.712')]\u001b[0m\n","\u001b[36m[2024-01-06 06:06:04,304][00204] Fps is (10 sec: 3276.7, 60 sec: 2935.5, 300 sec: 2691.7). Total num frames: 471040. Throughput: 0: 720.3. Samples: 118016. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:06:04,308][00204] Avg episode reward: [(0, '4.564')]\u001b[0m\n","\u001b[36m[2024-01-06 06:06:09,307][00204] Fps is (10 sec: 2456.8, 60 sec: 2935.3, 300 sec: 2685.1). Total num frames: 483328. Throughput: 0: 732.7. Samples: 121598. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:06:09,315][00204] Avg episode reward: [(0, '4.464')]\u001b[0m\n","\u001b[36m[2024-01-06 06:06:14,304][00204] Fps is (10 sec: 2867.3, 60 sec: 2867.2, 300 sec: 2701.1). Total num frames: 499712. Throughput: 0: 751.5. Samples: 123472. Policy #0 lag: (min: 0.0, avg: 0.4, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:06:14,312][00204] Avg episode reward: [(0, '4.543')]\u001b[0m\n","\u001b[36m[2024-01-06 06:06:19,304][00204] Fps is (10 sec: 3687.6, 60 sec: 3003.7, 300 sec: 2737.9). Total num frames: 520192. Throughput: 0: 783.0. Samples: 129038. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:06:19,307][00204] Avg episode reward: [(0, '4.461')]\u001b[0m\n","\u001b[36m[2024-01-06 06:06:24,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3072.0, 300 sec: 2751.7). Total num frames: 536576. Throughput: 0: 771.4. Samples: 134288. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:06:24,310][00204] Avg episode reward: [(0, '4.676')]\u001b[0m\n","\u001b[36m[2024-01-06 06:06:29,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3140.3, 300 sec: 2744.3). Total num frames: 548864. Throughput: 0: 764.8. Samples: 136128. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:06:29,307][00204] Avg episode reward: [(0, '4.589')]\u001b[0m\n","\u001b[36m[2024-01-06 06:06:34,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3072.0, 300 sec: 2737.3). Total num frames: 561152. Throughput: 0: 760.9. Samples: 139706. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:06:34,315][00204] Avg episode reward: [(0, '4.578')]\u001b[0m\n","\u001b[36m[2024-01-06 06:06:39,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3003.8, 300 sec: 2750.2). Total num frames: 577536. Throughput: 0: 779.3. Samples: 145120. Policy #0 lag: (min: 0.0, avg: 0.3, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:06:39,315][00204] Avg episode reward: [(0, '4.364')]\u001b[0m\n","\u001b[36m[2024-01-06 06:06:44,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3140.3, 300 sec: 2781.5). Total num frames: 598016. Throughput: 0: 778.9. Samples: 148006. Policy #0 lag: (min: 0.0, avg: 0.6, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:06:44,310][00204] Avg episode reward: [(0, '4.409')]\u001b[0m\n","\u001b[36m[2024-01-06 06:06:49,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3140.3, 300 sec: 2774.1). Total num frames: 610304. Throughput: 0: 758.0. Samples: 152126. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:06:49,307][00204] Avg episode reward: [(0, '4.416')]\u001b[0m\n","\u001b[36m[2024-01-06 06:06:54,304][00204] Fps is (10 sec: 2048.0, 60 sec: 3003.7, 300 sec: 2748.9). Total num frames: 618496. Throughput: 0: 742.3. Samples: 154998. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:06:54,311][00204] Avg episode reward: [(0, '4.345')]\u001b[0m\n","\u001b[36m[2024-01-06 06:06:59,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3003.7, 300 sec: 2778.2). Total num frames: 638976. Throughput: 0: 758.2. Samples: 157592. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:06:59,307][00204] Avg episode reward: [(0, '4.334')]\u001b[0m\n","\u001b[36m[2024-01-06 06:07:04,307][00204] Fps is (10 sec: 3685.2, 60 sec: 3071.8, 300 sec: 2788.7). Total num frames: 655360. Throughput: 0: 754.3. Samples: 162984. Policy #0 lag: (min: 0.0, avg: 0.4, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:07:04,316][00204] Avg episode reward: [(0, '4.445')]\u001b[0m\n","\u001b[36m[2024-01-06 06:07:09,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3072.2, 300 sec: 2781.9). Total num frames: 667648. Throughput: 0: 726.0. Samples: 166958. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:07:09,311][00204] Avg episode reward: [(0, '4.553')]\u001b[0m\n","\u001b[36m[2024-01-06 06:07:14,304][00204] Fps is (10 sec: 2048.7, 60 sec: 2935.5, 300 sec: 2758.5). Total num frames: 675840. Throughput: 0: 714.3. Samples: 168270. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:07:14,313][00204] Avg episode reward: [(0, '4.418')]\u001b[0m\n","\u001b[36m[2024-01-06 06:07:19,304][00204] Fps is (10 sec: 2457.6, 60 sec: 2867.2, 300 sec: 2768.9). Total num frames: 692224. Throughput: 0: 726.0. Samples: 172374. Policy #0 lag: (min: 0.0, avg: 0.4, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:07:19,310][00204] Avg episode reward: [(0, '4.660')]\u001b[0m\n","\u001b[36m[2024-01-06 06:07:24,304][00204] Fps is (10 sec: 2867.2, 60 sec: 2798.9, 300 sec: 2762.8). Total num frames: 704512. Throughput: 0: 705.3. Samples: 176858. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:07:24,307][00204] Avg episode reward: [(0, '4.551')]\u001b[0m\n","\u001b[36m[2024-01-06 06:07:29,304][00204] Fps is (10 sec: 2867.2, 60 sec: 2867.2, 300 sec: 2772.7). Total num frames: 720896. Throughput: 0: 696.6. Samples: 179352. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:07:29,306][00204] Avg episode reward: [(0, '4.702')]\u001b[0m\n","\u001b[36m[2024-01-06 06:07:34,304][00204] Fps is (10 sec: 2867.2, 60 sec: 2867.2, 300 sec: 2766.7). Total num frames: 733184. Throughput: 0: 687.2. Samples: 183050. Policy #0 lag: (min: 0.0, avg: 0.4, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:07:34,309][00204] Avg episode reward: [(0, '4.608')]\u001b[0m\n","\u001b[36m[2024-01-06 06:07:39,304][00204] Fps is (10 sec: 2867.2, 60 sec: 2867.2, 300 sec: 2776.2). Total num frames: 749568. Throughput: 0: 715.9. Samples: 187212. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:07:39,317][00204] Avg episode reward: [(0, '4.635')]\u001b[0m\n","\u001b[36m[2024-01-06 06:07:44,304][00204] Fps is (10 sec: 3276.8, 60 sec: 2798.9, 300 sec: 2785.3). Total num frames: 765952. Throughput: 0: 722.8. Samples: 190118. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:07:44,307][00204] Avg episode reward: [(0, '4.584')]\u001b[0m\n","\u001b[36m[2024-01-06 06:07:49,304][00204] Fps is (10 sec: 3276.8, 60 sec: 2867.2, 300 sec: 2794.1). Total num frames: 782336. Throughput: 0: 723.6. Samples: 195542. Policy #0 lag: (min: 0.0, avg: 0.4, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:07:49,316][00204] Avg episode reward: [(0, '4.651')]\u001b[0m\n","\u001b[36m[2024-01-06 06:07:54,304][00204] Fps is (10 sec: 2867.2, 60 sec: 2935.5, 300 sec: 2788.2). Total num frames: 794624. Throughput: 0: 714.6. Samples: 199116. Policy #0 lag: (min: 0.0, avg: 0.4, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:07:54,307][00204] Avg episode reward: [(0, '4.854')]\u001b[0m\n","\u001b[36m[2024-01-06 06:07:59,304][00204] Fps is (10 sec: 2457.6, 60 sec: 2798.9, 300 sec: 2782.5). Total num frames: 806912. Throughput: 0: 716.0. Samples: 200488. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:07:59,309][00204] Avg episode reward: [(0, '4.993')]\u001b[0m\n","\u001b[36m[2024-01-06 06:08:04,304][00204] Fps is (10 sec: 3276.8, 60 sec: 2867.4, 300 sec: 2804.7). Total num frames: 827392. Throughput: 0: 738.1. Samples: 205588. Policy #0 lag: (min: 0.0, avg: 0.4, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:08:04,307][00204] Avg episode reward: [(0, '4.851')]\u001b[0m\n","\u001b[36m[2024-01-06 06:08:09,307][00204] Fps is (10 sec: 3685.5, 60 sec: 2935.3, 300 sec: 2860.3). Total num frames: 843776. Throughput: 0: 759.3. Samples: 211030. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:08:09,317][00204] Avg episode reward: [(0, '4.671')]\u001b[0m\n","\u001b[36m[2024-01-06 06:08:14,308][00204] Fps is (10 sec: 2866.0, 60 sec: 3003.5, 300 sec: 2901.9). Total num frames: 856064. Throughput: 0: 743.3. Samples: 212802. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:08:14,311][00204] Avg episode reward: [(0, '4.537')]\u001b[0m\n","\u001b[36m[2024-01-06 06:08:19,304][00204] Fps is (10 sec: 2458.2, 60 sec: 2935.5, 300 sec: 2943.6). Total num frames: 868352. Throughput: 0: 742.4. Samples: 216460. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:08:19,313][00204] Avg episode reward: [(0, '4.669')]\u001b[0m\n","\u001b[36m[2024-01-06 06:08:24,304][00204] Fps is (10 sec: 2868.4, 60 sec: 3003.7, 300 sec: 2943.6). Total num frames: 884736. Throughput: 0: 765.0. Samples: 221636. Policy #0 lag: (min: 0.0, avg: 0.3, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:08:24,306][00204] Avg episode reward: [(0, '4.511')]\u001b[0m\n","\u001b[36m[2024-01-06 06:08:29,304][00204] Fps is (10 sec: 3686.5, 60 sec: 3072.0, 300 sec: 2957.5). Total num frames: 905216. Throughput: 0: 765.4. Samples: 224562. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:08:29,314][00204] Avg episode reward: [(0, '4.648')]\u001b[0m\n","\u001b[36m[2024-01-06 06:08:34,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3072.0, 300 sec: 2957.5). Total num frames: 917504. Throughput: 0: 744.7. Samples: 229054. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:08:34,308][00204] Avg episode reward: [(0, '4.609')]\u001b[0m\n","\u001b[36m[2024-01-06 06:08:39,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3003.7, 300 sec: 2957.5). Total num frames: 929792. Throughput: 0: 747.5. Samples: 232754. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:08:39,311][00204] Avg episode reward: [(0, '4.472')]\u001b[0m\n","\u001b[36m[2024-01-06 06:08:44,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3003.7, 300 sec: 2957.5). Total num frames: 946176. Throughput: 0: 758.6. Samples: 234624. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:08:44,307][00204] Avg episode reward: [(0, '4.410')]\u001b[0m\n","\u001b[36m[2024-01-06 06:08:49,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3072.0, 300 sec: 2957.5). Total num frames: 966656. Throughput: 0: 771.7. Samples: 240316. Policy #0 lag: (min: 0.0, avg: 0.4, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:08:49,306][00204] Avg episode reward: [(0, '4.583')]\u001b[0m\n","\u001b[36m[2024-01-06 06:08:54,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3072.0, 300 sec: 2957.5). Total num frames: 978944. Throughput: 0: 755.5. Samples: 245026. Policy #0 lag: (min: 0.0, avg: 0.4, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:08:54,309][00204] Avg episode reward: [(0, '4.692')]\u001b[0m\n","\u001b[36m[2024-01-06 06:08:59,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3072.0, 300 sec: 2957.5). Total num frames: 991232. Throughput: 0: 757.3. Samples: 246878. Policy #0 lag: (min: 0.0, avg: 0.4, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:08:59,311][00204] Avg episode reward: [(0, '4.752')]\u001b[0m\n","\u001b[36m[2024-01-06 06:09:04,305][00204] Fps is (10 sec: 2867.1, 60 sec: 3003.7, 300 sec: 2957.4). Total num frames: 1007616. Throughput: 0: 765.3. Samples: 250898. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:09:04,311][00204] Avg episode reward: [(0, '4.762')]\u001b[0m\n","\u001b[36m[2024-01-06 06:09:09,304][00204] Fps is (10 sec: 2867.2, 60 sec: 2935.6, 300 sec: 2929.7). Total num frames: 1019904. Throughput: 0: 762.8. Samples: 255964. Policy #0 lag: (min: 0.0, avg: 0.4, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:09:09,312][00204] Avg episode reward: [(0, '4.773')]\u001b[0m\n","\u001b[36m[2024-01-06 06:09:14,304][00204] Fps is (10 sec: 2867.3, 60 sec: 3003.9, 300 sec: 2943.6). Total num frames: 1036288. Throughput: 0: 743.0. Samples: 257996. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:09:14,313][00204] Avg episode reward: [(0, '4.778')]\u001b[0m\n","\u001b[36m[2024-01-06 06:09:19,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3003.7, 300 sec: 2943.6). Total num frames: 1048576. Throughput: 0: 725.6. Samples: 261704. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:09:19,311][00204] Avg episode reward: [(0, '4.786')]\u001b[0m\n","\u001b[36m[2024-01-06 06:09:24,304][00204] Fps is (10 sec: 2457.6, 60 sec: 2935.5, 300 sec: 2929.7). Total num frames: 1060864. Throughput: 0: 733.0. Samples: 265740. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:09:24,309][00204] Avg episode reward: [(0, '4.763')]\u001b[0m\n","\u001b[36m[2024-01-06 06:09:29,304][00204] Fps is (10 sec: 2867.2, 60 sec: 2867.2, 300 sec: 2929.7). Total num frames: 1077248. Throughput: 0: 750.1. Samples: 268380. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:09:29,313][00204] Avg episode reward: [(0, '4.658')]\u001b[0m\n","\u001b[36m[2024-01-06 06:09:34,304][00204] Fps is (10 sec: 3276.8, 60 sec: 2935.5, 300 sec: 2929.7). Total num frames: 1093632. Throughput: 0: 744.6. Samples: 273824. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:09:34,310][00204] Avg episode reward: [(0, '4.711')]\u001b[0m\n","\u001b[36m[2024-01-06 06:09:39,304][00204] Fps is (10 sec: 2867.2, 60 sec: 2935.5, 300 sec: 2943.6). Total num frames: 1105920. Throughput: 0: 720.5. Samples: 277448. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:09:39,307][00204] Avg episode reward: [(0, '4.840')]\u001b[0m\n","\u001b[36m[2024-01-06 06:09:44,304][00204] Fps is (10 sec: 2867.2, 60 sec: 2935.5, 300 sec: 2957.5). Total num frames: 1122304. Throughput: 0: 720.0. Samples: 279280. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:09:44,307][00204] Avg episode reward: [(0, '4.872')]\u001b[0m\n","\u001b[36m[2024-01-06 06:09:49,304][00204] Fps is (10 sec: 3276.8, 60 sec: 2867.2, 300 sec: 2957.5). Total num frames: 1138688. Throughput: 0: 741.0. Samples: 284242. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:09:49,307][00204] Avg episode reward: [(0, '4.899')]\u001b[0m\n","\u001b[36m[2024-01-06 06:09:54,308][00204] Fps is (10 sec: 3275.6, 60 sec: 2935.3, 300 sec: 2957.5). Total num frames: 1155072. Throughput: 0: 752.2. Samples: 289816. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:09:54,311][00204] Avg episode reward: [(0, '5.041')]\u001b[0m\n","\u001b[36m[2024-01-06 06:09:59,307][00204] Fps is (10 sec: 2866.5, 60 sec: 2935.3, 300 sec: 2957.4). Total num frames: 1167360. Throughput: 0: 747.1. Samples: 291616. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:09:59,309][00204] Avg episode reward: [(0, '4.978')]\u001b[0m\n","\u001b[36m[2024-01-06 06:10:04,307][00204] Fps is (10 sec: 2457.7, 60 sec: 2867.1, 300 sec: 2957.4). Total num frames: 1179648. Throughput: 0: 746.3. Samples: 295290. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:10:04,315][00204] Avg episode reward: [(0, '4.859')]\u001b[0m\n","\u001b[36m[2024-01-06 06:10:09,309][00204] Fps is (10 sec: 3276.1, 60 sec: 3003.5, 300 sec: 2957.4). Total num frames: 1200128. Throughput: 0: 766.4. Samples: 300232. Policy #0 lag: (min: 0.0, avg: 0.6, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:10:09,311][00204] Avg episode reward: [(0, '4.995')]\u001b[0m\n","\u001b[36m[2024-01-06 06:10:14,304][00204] Fps is (10 sec: 4097.2, 60 sec: 3072.0, 300 sec: 2985.2). Total num frames: 1220608. Throughput: 0: 770.4. Samples: 303050. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:10:14,307][00204] Avg episode reward: [(0, '5.046')]\u001b[0m\n","\u001b[36m[2024-01-06 06:10:19,307][00204] Fps is (10 sec: 3277.5, 60 sec: 3071.9, 300 sec: 2985.2). Total num frames: 1232896. Throughput: 0: 753.3. Samples: 307726. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:10:19,314][00204] Avg episode reward: [(0, '4.886')]\u001b[0m\n","\u001b[36m[2024-01-06 06:10:24,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3072.0, 300 sec: 2999.1). Total num frames: 1245184. Throughput: 0: 753.7. Samples: 311366. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:10:24,306][00204] Avg episode reward: [(0, '4.872')]\u001b[0m\n","\u001b[36m[2024-01-06 06:10:29,304][00204] Fps is (10 sec: 2867.9, 60 sec: 3072.0, 300 sec: 2999.1). Total num frames: 1261568. Throughput: 0: 755.2. Samples: 313262. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:10:29,307][00204] Avg episode reward: [(0, '5.052')]\u001b[0m\n","\u001b[36m[2024-01-06 06:10:34,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3072.0, 300 sec: 2985.2). Total num frames: 1277952. Throughput: 0: 773.3. Samples: 319040. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:10:34,325][00204] Avg episode reward: [(0, '5.525')]\u001b[0m\n","\u001b[36m[2024-01-06 06:10:39,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3140.3, 300 sec: 2999.1). Total num frames: 1294336. Throughput: 0: 756.9. Samples: 323876. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:10:39,309][00204] Avg episode reward: [(0, '5.221')]\u001b[0m\n","\u001b[36m[2024-01-06 06:10:44,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3072.0, 300 sec: 2999.1). Total num frames: 1306624. Throughput: 0: 757.2. Samples: 325690. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:10:44,310][00204] Avg episode reward: [(0, '5.570')]\u001b[0m\n","\u001b[36m[2024-01-06 06:10:49,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3003.7, 300 sec: 2985.2). Total num frames: 1318912. Throughput: 0: 753.8. Samples: 329210. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:10:49,307][00204] Avg episode reward: [(0, '5.315')]\u001b[0m\n","\u001b[36m[2024-01-06 06:10:54,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3072.2, 300 sec: 2985.2). Total num frames: 1339392. Throughput: 0: 774.8. Samples: 335096. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:10:54,306][00204] Avg episode reward: [(0, '5.456')]\u001b[0m\n","\u001b[36m[2024-01-06 06:10:59,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3140.4, 300 sec: 2999.1). Total num frames: 1355776. Throughput: 0: 777.7. Samples: 338046. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:10:59,308][00204] Avg episode reward: [(0, '5.205')]\u001b[0m\n","\u001b[36m[2024-01-06 06:11:04,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3140.4, 300 sec: 2999.1). Total num frames: 1368064. Throughput: 0: 759.6. Samples: 341908. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:11:04,307][00204] Avg episode reward: [(0, '5.394')]\u001b[0m\n","\u001b[36m[2024-01-06 06:11:09,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3004.0, 300 sec: 2985.2). Total num frames: 1380352. Throughput: 0: 760.1. Samples: 345572. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:11:09,306][00204] Avg episode reward: [(0, '5.634')]\u001b[0m\n","\u001b[36m[2024-01-06 06:11:14,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3003.7, 300 sec: 2985.2). Total num frames: 1400832. Throughput: 0: 777.1. Samples: 348232. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:11:14,315][00204] Avg episode reward: [(0, '5.880')]\u001b[0m\n","\u001b[36m[2024-01-06 06:11:19,308][00204] Fps is (10 sec: 3684.9, 60 sec: 3071.9, 300 sec: 2985.2). Total num frames: 1417216. Throughput: 0: 772.0. Samples: 353784. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:11:19,310][00204] Avg episode reward: [(0, '5.418')]\u001b[0m\n","\u001b[36m[2024-01-06 06:11:24,305][00204] Fps is (10 sec: 2867.0, 60 sec: 3072.0, 300 sec: 2985.2). Total num frames: 1429504. Throughput: 0: 753.0. Samples: 357762. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:11:24,309][00204] Avg episode reward: [(0, '5.471')]\u001b[0m\n","\u001b[36m[2024-01-06 06:11:29,309][00204] Fps is (10 sec: 2457.5, 60 sec: 3003.5, 300 sec: 2985.2). Total num frames: 1441792. Throughput: 0: 755.1. Samples: 359672. Policy #0 lag: (min: 0.0, avg: 0.3, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:11:29,311][00204] Avg episode reward: [(0, '5.453')]\u001b[0m\n","\u001b[36m[2024-01-06 06:11:34,304][00204] Fps is (10 sec: 3277.0, 60 sec: 3072.0, 300 sec: 2999.1). Total num frames: 1462272. Throughput: 0: 781.0. Samples: 364356. Policy #0 lag: (min: 0.0, avg: 0.6, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:11:34,306][00204] Avg episode reward: [(0, '5.655')]\u001b[0m\n","\u001b[36m[2024-01-06 06:11:39,304][00204] Fps is (10 sec: 3688.1, 60 sec: 3072.0, 300 sec: 2985.2). Total num frames: 1478656. Throughput: 0: 777.9. Samples: 370100. Policy #0 lag: (min: 0.0, avg: 0.6, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:11:39,306][00204] Avg episode reward: [(0, '5.755')]\u001b[0m\n","\u001b[36m[2024-01-06 06:11:44,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3072.0, 300 sec: 2985.2). Total num frames: 1490944. Throughput: 0: 762.2. Samples: 372346. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:11:44,308][00204] Avg episode reward: [(0, '5.715')]\u001b[0m\n","\u001b[36m[2024-01-06 06:11:49,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3072.0, 300 sec: 2999.1). Total num frames: 1503232. Throughput: 0: 758.0. Samples: 376016. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:11:49,309][00204] Avg episode reward: [(0, '5.645')]\u001b[0m\n","\u001b[36m[2024-01-06 06:11:54,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3003.7, 300 sec: 2985.2). Total num frames: 1519616. Throughput: 0: 778.0. Samples: 380580. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:11:54,307][00204] Avg episode reward: [(0, '5.699')]\u001b[0m\n","\u001b[36m[2024-01-06 06:11:59,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3072.0, 300 sec: 2999.1). Total num frames: 1540096. Throughput: 0: 785.1. Samples: 383562. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:11:59,312][00204] Avg episode reward: [(0, '5.773')]\u001b[0m\n","\u001b[36m[2024-01-06 06:12:04,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3140.3, 300 sec: 3013.0). Total num frames: 1556480. Throughput: 0: 774.1. Samples: 388614. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:12:04,311][00204] Avg episode reward: [(0, '6.211')]\u001b[0m\n","\u001b[36m[2024-01-06 06:12:09,306][00204] Fps is (10 sec: 2457.1, 60 sec: 3071.9, 300 sec: 3013.0). Total num frames: 1564672. Throughput: 0: 764.6. Samples: 392170. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:12:09,317][00204] Avg episode reward: [(0, '5.858')]\u001b[0m\n","\u001b[36m[2024-01-06 06:12:14,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3003.7, 300 sec: 3013.0). Total num frames: 1581056. Throughput: 0: 762.5. Samples: 393980. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:12:14,307][00204] Avg episode reward: [(0, '5.983')]\u001b[0m\n","\u001b[36m[2024-01-06 06:12:19,304][00204] Fps is (10 sec: 3687.1, 60 sec: 3072.2, 300 sec: 3040.8). Total num frames: 1601536. Throughput: 0: 785.6. Samples: 399706. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:12:19,316][00204] Avg episode reward: [(0, '5.791')]\u001b[0m\n","\u001b[36m[2024-01-06 06:12:24,307][00204] Fps is (10 sec: 3685.3, 60 sec: 3140.1, 300 sec: 3040.7). Total num frames: 1617920. Throughput: 0: 774.5. Samples: 404956. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:12:24,313][00204] Avg episode reward: [(0, '5.842')]\u001b[0m\n","\u001b[36m[2024-01-06 06:12:29,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3140.5, 300 sec: 3040.8). Total num frames: 1630208. Throughput: 0: 765.1. Samples: 406776. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:12:29,307][00204] Avg episode reward: [(0, '5.841')]\u001b[0m\n","\u001b[36m[2024-01-06 06:12:34,304][00204] Fps is (10 sec: 2458.3, 60 sec: 3003.7, 300 sec: 3026.9). Total num frames: 1642496. Throughput: 0: 766.9. Samples: 410528. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:12:34,307][00204] Avg episode reward: [(0, '5.774')]\u001b[0m\n","\u001b[36m[2024-01-06 06:12:39,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3072.0, 300 sec: 3040.8). Total num frames: 1662976. Throughput: 0: 787.4. Samples: 416014. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:12:39,307][00204] Avg episode reward: [(0, '5.829')]\u001b[0m\n","\u001b[36m[2024-01-06 06:12:44,308][00204] Fps is (10 sec: 3685.0, 60 sec: 3140.1, 300 sec: 3040.7). Total num frames: 1679360. Throughput: 0: 786.9. Samples: 418974. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:12:44,315][00204] Avg episode reward: [(0, '5.829')]\u001b[0m\n","\u001b[36m[2024-01-06 06:12:49,305][00204] Fps is (10 sec: 2867.0, 60 sec: 3140.2, 300 sec: 3040.8). Total num frames: 1691648. Throughput: 0: 767.9. Samples: 423170. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:12:49,307][00204] Avg episode reward: [(0, '5.885')]\u001b[0m\n","\u001b[36m[2024-01-06 06:12:54,308][00204] Fps is (10 sec: 2457.6, 60 sec: 3071.8, 300 sec: 3040.7). Total num frames: 1703936. Throughput: 0: 770.6. Samples: 426846. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:12:54,310][00204] Avg episode reward: [(0, '6.151')]\u001b[0m\n","\u001b[36m[2024-01-06 06:12:59,314][00204] Fps is (10 sec: 3273.9, 60 sec: 3071.5, 300 sec: 3040.7). Total num frames: 1724416. Throughput: 0: 786.5. Samples: 429378. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:12:59,322][00204] Avg episode reward: [(0, '6.334')]\u001b[0m\n","\u001b[36m[2024-01-06 06:13:04,304][00204] Fps is (10 sec: 4097.5, 60 sec: 3140.3, 300 sec: 3054.7). Total num frames: 1744896. Throughput: 0: 786.7. Samples: 435106. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:13:04,309][00204] Avg episode reward: [(0, '6.454')]\u001b[0m\n","\u001b[36m[2024-01-06 06:13:09,304][00204] Fps is (10 sec: 3279.9, 60 sec: 3208.6, 300 sec: 3054.7). Total num frames: 1757184. Throughput: 0: 765.3. Samples: 439392. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:13:09,309][00204] Avg episode reward: [(0, '6.305')]\u001b[0m\n","\u001b[36m[2024-01-06 06:13:14,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3140.3, 300 sec: 3054.6). Total num frames: 1769472. Throughput: 0: 765.3. Samples: 441216. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:13:14,313][00204] Avg episode reward: [(0, '6.651')]\u001b[0m\n","\u001b[36m[2024-01-06 06:13:19,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3072.0, 300 sec: 3054.6). Total num frames: 1785856. Throughput: 0: 775.2. Samples: 445412. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:13:19,307][00204] Avg episode reward: [(0, '6.708')]\u001b[0m\n","\u001b[36m[2024-01-06 06:13:24,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3072.1, 300 sec: 3040.8). Total num frames: 1802240. Throughput: 0: 781.2. Samples: 451166. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:13:24,313][00204] Avg episode reward: [(0, '7.393')]\u001b[0m\n","\u001b[36m[2024-01-06 06:13:29,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3140.3, 300 sec: 3054.6). Total num frames: 1818624. Throughput: 0: 772.4. Samples: 453730. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:13:29,308][00204] Avg episode reward: [(0, '7.474')]\u001b[0m\n","\u001b[36m[2024-01-06 06:13:34,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3140.3, 300 sec: 3054.6). Total num frames: 1830912. Throughput: 0: 760.1. Samples: 457376. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:13:34,313][00204] Avg episode reward: [(0, '8.032')]\u001b[0m\n","\u001b[36m[2024-01-06 06:13:39,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3072.0, 300 sec: 3054.6). Total num frames: 1847296. Throughput: 0: 771.1. Samples: 461542. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:13:39,311][00204] Avg episode reward: [(0, '8.128')]\u001b[0m\n","\u001b[36m[2024-01-06 06:13:44,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3072.2, 300 sec: 3040.8). Total num frames: 1863680. Throughput: 0: 778.0. Samples: 464382. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:13:44,313][00204] Avg episode reward: [(0, '8.355')]\u001b[0m\n","\u001b[36m[2024-01-06 06:13:49,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3140.3, 300 sec: 3054.6). Total num frames: 1880064. Throughput: 0: 771.6. Samples: 469828. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:13:49,311][00204] Avg episode reward: [(0, '8.253')]\u001b[0m\n","\u001b[36m[2024-01-06 06:13:54,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3140.4, 300 sec: 3054.6). Total num frames: 1892352. Throughput: 0: 759.3. Samples: 473562. Policy #0 lag: (min: 0.0, avg: 0.4, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:13:54,308][00204] Avg episode reward: [(0, '8.289')]\u001b[0m\n","\u001b[36m[2024-01-06 06:13:59,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3004.2, 300 sec: 3040.8). Total num frames: 1904640. Throughput: 0: 759.7. Samples: 475404. Policy #0 lag: (min: 0.0, avg: 0.4, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:13:59,313][00204] Avg episode reward: [(0, '8.060')]\u001b[0m\n","\u001b[36m[2024-01-06 06:14:04,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3003.7, 300 sec: 3068.5). Total num frames: 1925120. Throughput: 0: 781.6. Samples: 480586. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:14:04,307][00204] Avg episode reward: [(0, '8.617')]\u001b[0m\n","\u001b[36m[2024-01-06 06:14:09,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3072.0, 300 sec: 3068.5). Total num frames: 1941504. Throughput: 0: 776.9. Samples: 486128. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:14:09,308][00204] Avg episode reward: [(0, '8.560')]\u001b[0m\n","\u001b[36m[2024-01-06 06:14:14,305][00204] Fps is (10 sec: 2867.1, 60 sec: 3072.0, 300 sec: 3068.5). Total num frames: 1953792. Throughput: 0: 762.1. Samples: 488026. Policy #0 lag: (min: 0.0, avg: 0.3, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:14:14,312][00204] Avg episode reward: [(0, '8.728')]\u001b[0m\n","\u001b[36m[2024-01-06 06:14:19,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3003.7, 300 sec: 3068.5). Total num frames: 1966080. Throughput: 0: 762.7. Samples: 491696. Policy #0 lag: (min: 0.0, avg: 0.3, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:14:19,308][00204] Avg episode reward: [(0, '8.442')]\u001b[0m\n","\u001b[36m[2024-01-06 06:14:24,304][00204] Fps is (10 sec: 3276.9, 60 sec: 3072.0, 300 sec: 3082.4). Total num frames: 1986560. Throughput: 0: 782.7. Samples: 496764. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:14:24,306][00204] Avg episode reward: [(0, '8.917')]\u001b[0m\n","\u001b[36m[2024-01-06 06:14:29,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3072.0, 300 sec: 3082.4). Total num frames: 2002944. Throughput: 0: 780.2. Samples: 499492. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:14:29,311][00204] Avg episode reward: [(0, '9.012')]\u001b[0m\n","\u001b[36m[2024-01-06 06:14:34,311][00204] Fps is (10 sec: 2865.4, 60 sec: 3071.7, 300 sec: 3082.3). Total num frames: 2015232. Throughput: 0: 764.3. Samples: 504228. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:14:34,321][00204] Avg episode reward: [(0, '8.990')]\u001b[0m\n","\u001b[36m[2024-01-06 06:14:39,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3003.7, 300 sec: 3068.5). Total num frames: 2027520. Throughput: 0: 762.7. Samples: 507882. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:14:39,307][00204] Avg episode reward: [(0, '8.616')]\u001b[0m\n","\u001b[36m[2024-01-06 06:14:44,304][00204] Fps is (10 sec: 3278.9, 60 sec: 3072.0, 300 sec: 3082.4). Total num frames: 2048000. Throughput: 0: 769.2. Samples: 510020. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:14:44,307][00204] Avg episode reward: [(0, '8.620')]\u001b[0m\n","\u001b[36m[2024-01-06 06:14:49,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3072.0, 300 sec: 3082.4). Total num frames: 2064384. Throughput: 0: 782.0. Samples: 515776. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:14:49,314][00204] Avg episode reward: [(0, '9.229')]\u001b[0m\n","\u001b[36m[2024-01-06 06:14:54,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3140.3, 300 sec: 3096.3). Total num frames: 2080768. Throughput: 0: 765.6. Samples: 520578. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:14:54,310][00204] Avg episode reward: [(0, '9.439')]\u001b[0m\n","\u001b[36m[2024-01-06 06:14:59,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3140.3, 300 sec: 3096.3). Total num frames: 2093056. Throughput: 0: 761.1. Samples: 522274. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:14:59,312][00204] Avg episode reward: [(0, '9.460')]\u001b[0m\n","\u001b[36m[2024-01-06 06:15:04,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3072.0, 300 sec: 3082.5). Total num frames: 2109440. Throughput: 0: 763.8. Samples: 526068. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:15:04,313][00204] Avg episode reward: [(0, '9.767')]\u001b[0m\n","\u001b[36m[2024-01-06 06:15:09,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3072.0, 300 sec: 3068.5). Total num frames: 2125824. Throughput: 0: 778.8. Samples: 531810. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:15:09,307][00204] Avg episode reward: [(0, '9.427')]\u001b[0m\n","\u001b[36m[2024-01-06 06:15:14,308][00204] Fps is (10 sec: 3275.6, 60 sec: 3140.1, 300 sec: 3082.4). Total num frames: 2142208. Throughput: 0: 781.2. Samples: 534650. Policy #0 lag: (min: 0.0, avg: 0.7, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:15:14,315][00204] Avg episode reward: [(0, '9.770')]\u001b[0m\n","\u001b[36m[2024-01-06 06:15:19,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3140.3, 300 sec: 3082.4). Total num frames: 2154496. Throughput: 0: 760.3. Samples: 538436. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:15:19,308][00204] Avg episode reward: [(0, '10.506')]\u001b[0m\n","\u001b[36m[2024-01-06 06:15:24,304][00204] Fps is (10 sec: 2458.5, 60 sec: 3003.7, 300 sec: 3068.5). Total num frames: 2166784. Throughput: 0: 764.5. Samples: 542284. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:15:24,306][00204] Avg episode reward: [(0, '11.180')]\u001b[0m\n","\u001b[36m[2024-01-06 06:15:29,305][00204] Fps is (10 sec: 3276.7, 60 sec: 3072.0, 300 sec: 3082.4). Total num frames: 2187264. Throughput: 0: 779.5. Samples: 545098. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:15:29,307][00204] Avg episode reward: [(0, '12.568')]\u001b[0m\n","\u001b[36m[2024-01-06 06:15:34,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3140.6, 300 sec: 3082.4). Total num frames: 2203648. Throughput: 0: 779.1. Samples: 550836. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:15:34,311][00204] Avg episode reward: [(0, '12.574')]\u001b[0m\n","\u001b[36m[2024-01-06 06:15:39,304][00204] Fps is (10 sec: 2867.3, 60 sec: 3140.3, 300 sec: 3082.4). Total num frames: 2215936. Throughput: 0: 757.1. Samples: 554646. Policy #0 lag: (min: 0.0, avg: 0.6, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:15:39,312][00204] Avg episode reward: [(0, '12.988')]\u001b[0m\n","\u001b[36m[2024-01-06 06:15:44,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3003.7, 300 sec: 3082.4). Total num frames: 2228224. Throughput: 0: 759.5. Samples: 556450. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:15:44,312][00204] Avg episode reward: [(0, '11.607')]\u001b[0m\n","\u001b[36m[2024-01-06 06:15:49,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3072.0, 300 sec: 3082.4). Total num frames: 2248704. Throughput: 0: 782.4. Samples: 561276. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:15:49,307][00204] Avg episode reward: [(0, '10.832')]\u001b[0m\n","\u001b[36m[2024-01-06 06:15:54,304][00204] Fps is (10 sec: 4096.0, 60 sec: 3140.3, 300 sec: 3096.3). Total num frames: 2269184. Throughput: 0: 783.5. Samples: 567066. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:15:54,307][00204] Avg episode reward: [(0, '11.271')]\u001b[0m\n","\u001b[36m[2024-01-06 06:15:59,308][00204] Fps is (10 sec: 3275.4, 60 sec: 3140.0, 300 sec: 3096.3). Total num frames: 2281472. Throughput: 0: 768.7. Samples: 569242. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:15:59,311][00204] Avg episode reward: [(0, '11.060')]\u001b[0m\n","\u001b[36m[2024-01-06 06:16:04,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 2293760. Throughput: 0: 767.8. Samples: 572988. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:16:04,312][00204] Avg episode reward: [(0, '11.113')]\u001b[0m\n","\u001b[36m[2024-01-06 06:16:09,304][00204] Fps is (10 sec: 2868.4, 60 sec: 3072.0, 300 sec: 3082.4). Total num frames: 2310144. Throughput: 0: 786.9. Samples: 577694. Policy #0 lag: (min: 0.0, avg: 0.4, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:16:09,314][00204] Avg episode reward: [(0, '11.961')]\u001b[0m\n","\u001b[36m[2024-01-06 06:16:14,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3140.5, 300 sec: 3096.3). Total num frames: 2330624. Throughput: 0: 786.8. Samples: 580504. Policy #0 lag: (min: 0.0, avg: 0.4, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:16:14,313][00204] Avg episode reward: [(0, '12.804')]\u001b[0m\n","\u001b[36m[2024-01-06 06:16:19,308][00204] Fps is (10 sec: 3275.4, 60 sec: 3140.0, 300 sec: 3096.3). Total num frames: 2342912. Throughput: 0: 771.9. Samples: 585574. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:16:19,316][00204] Avg episode reward: [(0, '12.283')]\u001b[0m\n","\u001b[36m[2024-01-06 06:16:24,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3140.3, 300 sec: 3096.3). Total num frames: 2355200. Throughput: 0: 769.3. Samples: 589266. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:16:24,308][00204] Avg episode reward: [(0, '13.049')]\u001b[0m\n","\u001b[36m[2024-01-06 06:16:29,304][00204] Fps is (10 sec: 2868.4, 60 sec: 3072.0, 300 sec: 3082.4). Total num frames: 2371584. Throughput: 0: 769.7. Samples: 591088. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:16:29,314][00204] Avg episode reward: [(0, '13.261')]\u001b[0m\n","\u001b[36m[2024-01-06 06:16:34,306][00204] Fps is (10 sec: 3685.6, 60 sec: 3140.2, 300 sec: 3096.3). Total num frames: 2392064. Throughput: 0: 786.7. Samples: 596680. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:16:34,310][00204] Avg episode reward: [(0, '13.090')]\u001b[0m\n","\u001b[36m[2024-01-06 06:16:39,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3140.3, 300 sec: 3096.3). Total num frames: 2404352. Throughput: 0: 772.3. Samples: 601818. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:16:39,313][00204] Avg episode reward: [(0, '13.213')]\u001b[0m\n","\u001b[36m[2024-01-06 06:16:44,305][00204] Fps is (10 sec: 2457.9, 60 sec: 3140.2, 300 sec: 3096.3). Total num frames: 2416640. Throughput: 0: 764.8. Samples: 603656. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:16:44,316][00204] Avg episode reward: [(0, '13.718')]\u001b[0m\n","\u001b[36m[2024-01-06 06:16:49,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3003.7, 300 sec: 3082.4). Total num frames: 2428928. Throughput: 0: 758.3. Samples: 607112. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:16:49,307][00204] Avg episode reward: [(0, '13.707')]\u001b[0m\n","\u001b[36m[2024-01-06 06:16:54,304][00204] Fps is (10 sec: 3277.2, 60 sec: 3003.7, 300 sec: 3082.4). Total num frames: 2449408. Throughput: 0: 778.2. Samples: 612712. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:16:54,307][00204] Avg episode reward: [(0, '14.992')]\u001b[0m\n","\u001b[36m[2024-01-06 06:16:59,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3072.2, 300 sec: 3082.4). Total num frames: 2465792. Throughput: 0: 776.7. Samples: 615454. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:16:59,310][00204] Avg episode reward: [(0, '15.489')]\u001b[0m\n","\u001b[36m[2024-01-06 06:17:04,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 2478080. Throughput: 0: 755.7. Samples: 619578. Policy #0 lag: (min: 0.0, avg: 0.3, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:17:04,312][00204] Avg episode reward: [(0, '15.697')]\u001b[0m\n","\u001b[36m[2024-01-06 06:17:09,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3003.7, 300 sec: 3082.4). Total num frames: 2490368. Throughput: 0: 755.7. Samples: 623274. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:17:09,315][00204] Avg episode reward: [(0, '14.688')]\u001b[0m\n","\u001b[36m[2024-01-06 06:17:14,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3003.7, 300 sec: 3082.4). Total num frames: 2510848. Throughput: 0: 775.1. Samples: 625966. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:17:14,306][00204] Avg episode reward: [(0, '14.457')]\u001b[0m\n","\u001b[36m[2024-01-06 06:17:19,304][00204] Fps is (10 sec: 4096.0, 60 sec: 3140.5, 300 sec: 3096.3). Total num frames: 2531328. Throughput: 0: 778.1. Samples: 631694. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:17:19,307][00204] Avg episode reward: [(0, '14.932')]\u001b[0m\n","\u001b[36m[2024-01-06 06:17:24,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3140.3, 300 sec: 3096.3). Total num frames: 2543616. Throughput: 0: 761.7. Samples: 636096. Policy #0 lag: (min: 0.0, avg: 0.4, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:17:24,310][00204] Avg episode reward: [(0, '15.556')]\u001b[0m\n","\u001b[36m[2024-01-06 06:17:29,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 2555904. Throughput: 0: 761.6. Samples: 637928. Policy #0 lag: (min: 0.0, avg: 0.4, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:17:29,307][00204] Avg episode reward: [(0, '16.074')]\u001b[0m\n","\u001b[36m[2024-01-06 06:17:34,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3003.8, 300 sec: 3082.4). Total num frames: 2572288. Throughput: 0: 783.2. Samples: 642358. Policy #0 lag: (min: 0.0, avg: 0.4, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:17:34,306][00204] Avg episode reward: [(0, '17.294')]\u001b[0m\n","\u001b[36m[2024-01-06 06:17:39,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3140.3, 300 sec: 3096.3). Total num frames: 2592768. Throughput: 0: 784.9. Samples: 648034. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:17:39,307][00204] Avg episode reward: [(0, '18.019')]\u001b[0m\n","\u001b[36m[2024-01-06 06:17:44,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3140.3, 300 sec: 3096.3). Total num frames: 2605056. Throughput: 0: 777.8. Samples: 650454. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:17:44,313][00204] Avg episode reward: [(0, '18.814')]\u001b[0m\n","\u001b[36m[2024-01-06 06:17:49,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3140.3, 300 sec: 3096.3). Total num frames: 2617344. Throughput: 0: 766.6. Samples: 654074. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:17:49,306][00204] Avg episode reward: [(0, '18.512')]\u001b[0m\n","\u001b[36m[2024-01-06 06:17:54,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3072.0, 300 sec: 3082.5). Total num frames: 2633728. Throughput: 0: 782.8. Samples: 658500. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:17:54,312][00204] Avg episode reward: [(0, '17.373')]\u001b[0m\n","\u001b[36m[2024-01-06 06:17:59,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3140.3, 300 sec: 3082.4). Total num frames: 2654208. Throughput: 0: 786.4. Samples: 661352. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:17:59,314][00204] Avg episode reward: [(0, '16.686')]\u001b[0m\n","\u001b[36m[2024-01-06 06:18:04,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3140.3, 300 sec: 3082.4). Total num frames: 2666496. Throughput: 0: 776.1. Samples: 666620. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:18:04,307][00204] Avg episode reward: [(0, '16.435')]\u001b[0m\n","\u001b[36m[2024-01-06 06:18:09,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3140.3, 300 sec: 3082.4). Total num frames: 2678784. Throughput: 0: 759.9. Samples: 670290. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:18:09,310][00204] Avg episode reward: [(0, '15.910')]\u001b[0m\n","\u001b[36m[2024-01-06 06:18:14,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3072.0, 300 sec: 3082.4). Total num frames: 2695168. Throughput: 0: 760.5. Samples: 672152. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:18:14,314][00204] Avg episode reward: [(0, '16.023')]\u001b[0m\n","\u001b[36m[2024-01-06 06:18:19,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 2715648. Throughput: 0: 782.3. Samples: 677562. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:18:19,314][00204] Avg episode reward: [(0, '16.342')]\u001b[0m\n","\u001b[36m[2024-01-06 06:18:24,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3140.3, 300 sec: 3096.3). Total num frames: 2732032. Throughput: 0: 776.7. Samples: 682986. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:18:24,308][00204] Avg episode reward: [(0, '16.858')]\u001b[0m\n","\u001b[36m[2024-01-06 06:18:29,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3072.0, 300 sec: 3082.4). Total num frames: 2740224. Throughput: 0: 762.9. Samples: 684786. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:18:29,308][00204] Avg episode reward: [(0, '17.115')]\u001b[0m\n","\u001b[36m[2024-01-06 06:18:34,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3072.0, 300 sec: 3082.4). Total num frames: 2756608. Throughput: 0: 764.6. Samples: 688480. Policy #0 lag: (min: 0.0, avg: 0.4, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:18:34,311][00204] Avg episode reward: [(0, '16.951')]\u001b[0m\n","\u001b[36m[2024-01-06 06:18:39,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 2777088. Throughput: 0: 787.6. Samples: 693940. Policy #0 lag: (min: 0.0, avg: 0.4, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:18:39,313][00204] Avg episode reward: [(0, '16.465')]\u001b[0m\n","\u001b[36m[2024-01-06 06:18:44,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3140.3, 300 sec: 3096.3). Total num frames: 2793472. Throughput: 0: 789.6. Samples: 696886. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:18:44,307][00204] Avg episode reward: [(0, '15.913')]\u001b[0m\n","\u001b[36m[2024-01-06 06:18:49,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3140.3, 300 sec: 3096.3). Total num frames: 2805760. Throughput: 0: 768.4. Samples: 701200. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:18:49,309][00204] Avg episode reward: [(0, '16.003')]\u001b[0m\n","\u001b[36m[2024-01-06 06:18:54,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 2818048. Throughput: 0: 769.5. Samples: 704916. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:18:54,309][00204] Avg episode reward: [(0, '16.194')]\u001b[0m\n","\u001b[36m[2024-01-06 06:18:59,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 2838528. Throughput: 0: 783.4. Samples: 707404. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:18:59,307][00204] Avg episode reward: [(0, '16.990')]\u001b[0m\n","\u001b[36m[2024-01-06 06:19:04,305][00204] Fps is (10 sec: 3686.2, 60 sec: 3140.2, 300 sec: 3096.3). Total num frames: 2854912. Throughput: 0: 789.9. Samples: 713110. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:19:04,311][00204] Avg episode reward: [(0, '17.881')]\u001b[0m\n","\u001b[36m[2024-01-06 06:19:09,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3140.3, 300 sec: 3096.3). Total num frames: 2867200. Throughput: 0: 768.3. Samples: 717560. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:19:09,316][00204] Avg episode reward: [(0, '18.460')]\u001b[0m\n","\u001b[36m[2024-01-06 06:19:14,305][00204] Fps is (10 sec: 2457.6, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 2879488. Throughput: 0: 769.7. Samples: 719424. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:19:14,314][00204] Avg episode reward: [(0, '19.148')]\u001b[0m\n","\u001b[36m[2024-01-06 06:19:19,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3003.7, 300 sec: 3082.4). Total num frames: 2895872. Throughput: 0: 782.3. Samples: 723684. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:19:19,313][00204] Avg episode reward: [(0, '18.785')]\u001b[0m\n","\u001b[36m[2024-01-06 06:19:24,304][00204] Fps is (10 sec: 3686.6, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 2916352. Throughput: 0: 792.6. Samples: 729606. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:19:24,307][00204] Avg episode reward: [(0, '18.459')]\u001b[0m\n","\u001b[36m[2024-01-06 06:19:29,304][00204] Fps is (10 sec: 3686.3, 60 sec: 3208.5, 300 sec: 3110.2). Total num frames: 2932736. Throughput: 0: 782.8. Samples: 732112. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:19:29,313][00204] Avg episode reward: [(0, '17.115')]\u001b[0m\n","\u001b[36m[2024-01-06 06:19:34,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3140.3, 300 sec: 3110.2). Total num frames: 2945024. Throughput: 0: 769.2. Samples: 735812. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:19:34,308][00204] Avg episode reward: [(0, '16.942')]\u001b[0m\n","\u001b[36m[2024-01-06 06:19:39,304][00204] Fps is (10 sec: 2867.3, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 2961408. Throughput: 0: 780.5. Samples: 740038. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:19:39,315][00204] Avg episode reward: [(0, '17.013')]\u001b[0m\n","\u001b[36m[2024-01-06 06:19:44,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 2977792. Throughput: 0: 791.4. Samples: 743018. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:19:44,307][00204] Avg episode reward: [(0, '17.483')]\u001b[0m\n","\u001b[36m[2024-01-06 06:19:49,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3140.3, 300 sec: 3096.3). Total num frames: 2994176. Throughput: 0: 788.3. Samples: 748582. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:19:49,313][00204] Avg episode reward: [(0, '19.412')]\u001b[0m\n","\u001b[36m[2024-01-06 06:19:54,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3140.3, 300 sec: 3096.3). Total num frames: 3006464. Throughput: 0: 768.9. Samples: 752160. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:19:54,312][00204] Avg episode reward: [(0, '19.377')]\u001b[0m\n","\u001b[36m[2024-01-06 06:19:59,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3003.7, 300 sec: 3082.4). Total num frames: 3018752. Throughput: 0: 769.0. Samples: 754030. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:19:59,317][00204] Avg episode reward: [(0, '20.828')]\u001b[0m\n","\u001b[36m[2024-01-06 06:20:04,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 3039232. Throughput: 0: 787.0. Samples: 759098. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:20:04,307][00204] Avg episode reward: [(0, '19.524')]\u001b[0m\n","\u001b[36m[2024-01-06 06:20:09,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3140.3, 300 sec: 3096.3). Total num frames: 3055616. Throughput: 0: 782.0. Samples: 764796. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:20:09,306][00204] Avg episode reward: [(0, '19.291')]\u001b[0m\n","\u001b[36m[2024-01-06 06:20:14,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3140.3, 300 sec: 3096.3). Total num frames: 3067904. Throughput: 0: 766.1. Samples: 766588. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:20:14,308][00204] Avg episode reward: [(0, '19.683')]\u001b[0m\n","\u001b[36m[2024-01-06 06:20:19,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 3080192. Throughput: 0: 763.7. Samples: 770178. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:20:19,307][00204] Avg episode reward: [(0, '19.032')]\u001b[0m\n","\u001b[36m[2024-01-06 06:20:24,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 3100672. Throughput: 0: 783.0. Samples: 775272. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:20:24,307][00204] Avg episode reward: [(0, '19.885')]\u001b[0m\n","\u001b[36m[2024-01-06 06:20:29,305][00204] Fps is (10 sec: 4095.8, 60 sec: 3140.3, 300 sec: 3110.2). Total num frames: 3121152. Throughput: 0: 778.9. Samples: 778068. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:20:29,311][00204] Avg episode reward: [(0, '19.260')]\u001b[0m\n","\u001b[36m[2024-01-06 06:20:34,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3140.3, 300 sec: 3110.2). Total num frames: 3133440. Throughput: 0: 759.8. Samples: 782774. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:20:34,307][00204] Avg episode reward: [(0, '19.684')]\u001b[0m\n","\u001b[36m[2024-01-06 06:20:39,304][00204] Fps is (10 sec: 2457.7, 60 sec: 3072.0, 300 sec: 3110.2). Total num frames: 3145728. Throughput: 0: 763.2. Samples: 786506. Policy #0 lag: (min: 0.0, avg: 0.3, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:20:39,308][00204] Avg episode reward: [(0, '20.244')]\u001b[0m\n","\u001b[36m[2024-01-06 06:20:44,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 3162112. Throughput: 0: 771.6. Samples: 788750. Policy #0 lag: (min: 0.0, avg: 0.3, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:20:44,307][00204] Avg episode reward: [(0, '20.023')]\u001b[0m\n","\u001b[36m[2024-01-06 06:20:49,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3140.3, 300 sec: 3096.3). Total num frames: 3182592. Throughput: 0: 787.0. Samples: 794514. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:20:49,315][00204] Avg episode reward: [(0, '19.544')]\u001b[0m\n","\u001b[36m[2024-01-06 06:20:54,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3140.3, 300 sec: 3096.3). Total num frames: 3194880. Throughput: 0: 764.9. Samples: 799216. Policy #0 lag: (min: 0.0, avg: 0.3, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:20:54,320][00204] Avg episode reward: [(0, '18.702')]\u001b[0m\n","\u001b[36m[2024-01-06 06:20:59,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3140.3, 300 sec: 3096.3). Total num frames: 3207168. Throughput: 0: 767.2. Samples: 801112. Policy #0 lag: (min: 0.0, avg: 0.3, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:20:59,307][00204] Avg episode reward: [(0, '18.336')]\u001b[0m\n","\u001b[36m[2024-01-06 06:21:04,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 3223552. Throughput: 0: 775.6. Samples: 805082. Policy #0 lag: (min: 0.0, avg: 0.3, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:21:04,307][00204] Avg episode reward: [(0, '18.780')]\u001b[0m\n","\u001b[36m[2024-01-06 06:21:09,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3140.3, 300 sec: 3096.3). Total num frames: 3244032. Throughput: 0: 792.3. Samples: 810926. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:21:09,307][00204] Avg episode reward: [(0, '18.145')]\u001b[0m\n","\u001b[36m[2024-01-06 06:21:14,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3140.3, 300 sec: 3096.3). Total num frames: 3256320. Throughput: 0: 792.8. Samples: 813744. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:21:14,313][00204] Avg episode reward: [(0, '19.601')]\u001b[0m\n","\u001b[36m[2024-01-06 06:21:19,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3140.3, 300 sec: 3096.3). Total num frames: 3268608. Throughput: 0: 770.0. Samples: 817422. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:21:19,307][00204] Avg episode reward: [(0, '19.266')]\u001b[0m\n","\u001b[36m[2024-01-06 06:21:24,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 3284992. Throughput: 0: 774.4. Samples: 821352. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:21:24,307][00204] Avg episode reward: [(0, '19.064')]\u001b[0m\n","\u001b[36m[2024-01-06 06:21:29,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3003.8, 300 sec: 3082.4). Total num frames: 3301376. Throughput: 0: 785.1. Samples: 824080. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:21:29,308][00204] Avg episode reward: [(0, '19.797')]\u001b[0m\n","\u001b[36m[2024-01-06 06:21:34,308][00204] Fps is (10 sec: 3685.1, 60 sec: 3140.1, 300 sec: 3110.1). Total num frames: 3321856. Throughput: 0: 785.1. Samples: 829848. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:21:34,310][00204] Avg episode reward: [(0, '19.320')]\u001b[0m\n","\u001b[36m[2024-01-06 06:21:39,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3140.3, 300 sec: 3110.2). Total num frames: 3334144. Throughput: 0: 765.0. Samples: 833642. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:21:39,309][00204] Avg episode reward: [(0, '19.352')]\u001b[0m\n","\u001b[36m[2024-01-06 06:21:44,304][00204] Fps is (10 sec: 2458.5, 60 sec: 3072.0, 300 sec: 3110.2). Total num frames: 3346432. Throughput: 0: 763.7. Samples: 835480. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:21:44,311][00204] Avg episode reward: [(0, '18.333')]\u001b[0m\n","\u001b[36m[2024-01-06 06:21:49,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3003.7, 300 sec: 3096.3). Total num frames: 3362816. Throughput: 0: 782.3. Samples: 840284. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:21:49,306][00204] Avg episode reward: [(0, '19.415')]\u001b[0m\n","\u001b[36m[2024-01-06 06:21:54,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3140.3, 300 sec: 3110.2). Total num frames: 3383296. Throughput: 0: 783.3. Samples: 846176. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:21:54,309][00204] Avg episode reward: [(0, '20.375')]\u001b[0m\n","\u001b[36m[2024-01-06 06:21:59,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3140.3, 300 sec: 3110.2). Total num frames: 3395584. Throughput: 0: 767.4. Samples: 848276. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:21:59,309][00204] Avg episode reward: [(0, '20.526')]\u001b[0m\n","\u001b[36m[2024-01-06 06:22:04,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3072.0, 300 sec: 3110.2). Total num frames: 3407872. Throughput: 0: 765.1. Samples: 851850. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:22:04,315][00204] Avg episode reward: [(0, '20.659')]\u001b[0m\n","\u001b[36m[2024-01-06 06:22:09,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3072.0, 300 sec: 3110.2). Total num frames: 3428352. Throughput: 0: 786.9. Samples: 856762. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:22:09,307][00204] Avg episode reward: [(0, '21.195')]\u001b[0m\n","\u001b[36m[2024-01-06 06:22:14,304][00204] Fps is (10 sec: 3686.3, 60 sec: 3140.3, 300 sec: 3096.3). Total num frames: 3444736. Throughput: 0: 788.5. Samples: 859562. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:22:14,310][00204] Avg episode reward: [(0, '20.794')]\u001b[0m\n","\u001b[36m[2024-01-06 06:22:19,309][00204] Fps is (10 sec: 2865.9, 60 sec: 3140.0, 300 sec: 3096.2). Total num frames: 3457024. Throughput: 0: 769.2. Samples: 864464. Policy #0 lag: (min: 0.0, avg: 0.6, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:22:19,316][00204] Avg episode reward: [(0, '19.382')]\u001b[0m\n","\u001b[36m[2024-01-06 06:22:24,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 3469312. Throughput: 0: 768.7. Samples: 868232. Policy #0 lag: (min: 0.0, avg: 0.6, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:22:24,306][00204] Avg episode reward: [(0, '18.472')]\u001b[0m\n","\u001b[36m[2024-01-06 06:22:29,304][00204] Fps is (10 sec: 2868.5, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 3485696. Throughput: 0: 768.8. Samples: 870076. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:22:29,307][00204] Avg episode reward: [(0, '18.886')]\u001b[0m\n","\u001b[36m[2024-01-06 06:22:34,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3072.2, 300 sec: 3096.3). Total num frames: 3506176. Throughput: 0: 791.4. Samples: 875898. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:22:34,307][00204] Avg episode reward: [(0, '18.085')]\u001b[0m\n","\u001b[36m[2024-01-06 06:22:39,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3140.3, 300 sec: 3110.2). Total num frames: 3522560. Throughput: 0: 771.2. Samples: 880882. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:22:39,307][00204] Avg episode reward: [(0, '18.130')]\u001b[0m\n","\u001b[36m[2024-01-06 06:22:44,307][00204] Fps is (10 sec: 2866.5, 60 sec: 3140.1, 300 sec: 3110.2). Total num frames: 3534848. Throughput: 0: 764.9. Samples: 882700. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:22:44,315][00204] Avg episode reward: [(0, '18.752')]\u001b[0m\n","\u001b[36m[2024-01-06 06:22:49,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 3547136. Throughput: 0: 767.9. Samples: 886404. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:22:49,311][00204] Avg episode reward: [(0, '20.320')]\u001b[0m\n","\u001b[36m[2024-01-06 06:22:54,304][00204] Fps is (10 sec: 3277.6, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 3567616. Throughput: 0: 784.8. Samples: 892078. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:22:54,307][00204] Avg episode reward: [(0, '21.379')]\u001b[0m\n","\u001b[36m[2024-01-06 06:22:59,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3140.3, 300 sec: 3110.2). Total num frames: 3584000. Throughput: 0: 785.4. Samples: 894904. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:22:59,316][00204] Avg episode reward: [(0, '20.132')]\u001b[0m\n","\u001b[36m[2024-01-06 06:23:04,308][00204] Fps is (10 sec: 2866.2, 60 sec: 3140.1, 300 sec: 3110.1). Total num frames: 3596288. Throughput: 0: 762.5. Samples: 898776. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:23:04,311][00204] Avg episode reward: [(0, '22.216')]\u001b[0m\n","\u001b[36m[2024-01-06 06:23:09,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3003.7, 300 sec: 3096.3). Total num frames: 3608576. Throughput: 0: 763.1. Samples: 902570. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:23:09,309][00204] Avg episode reward: [(0, '22.182')]\u001b[0m\n","\u001b[36m[2024-01-06 06:23:14,304][00204] Fps is (10 sec: 3277.9, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 3629056. Throughput: 0: 785.6. Samples: 905426. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:23:14,310][00204] Avg episode reward: [(0, '20.115')]\u001b[0m\n","\u001b[36m[2024-01-06 06:23:19,307][00204] Fps is (10 sec: 3685.3, 60 sec: 3140.4, 300 sec: 3096.3). Total num frames: 3645440. Throughput: 0: 782.8. Samples: 911128. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:23:19,315][00204] Avg episode reward: [(0, '19.063')]\u001b[0m\n","\u001b[36m[2024-01-06 06:23:24,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3140.2, 300 sec: 3110.2). Total num frames: 3657728. Throughput: 0: 760.2. Samples: 915090. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:23:24,313][00204] Avg episode reward: [(0, '20.364')]\u001b[0m\n","\u001b[36m[2024-01-06 06:23:29,304][00204] Fps is (10 sec: 2458.3, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 3670016. Throughput: 0: 760.9. Samples: 916940. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:23:29,307][00204] Avg episode reward: [(0, '20.640')]\u001b[0m\n","\u001b[36m[2024-01-06 06:23:34,304][00204] Fps is (10 sec: 3276.9, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 3690496. Throughput: 0: 786.1. Samples: 921778. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:23:34,307][00204] Avg episode reward: [(0, '20.664')]\u001b[0m\n","\u001b[36m[2024-01-06 06:23:39,304][00204] Fps is (10 sec: 4096.0, 60 sec: 3140.3, 300 sec: 3110.2). Total num frames: 3710976. Throughput: 0: 786.2. Samples: 927458. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:23:39,310][00204] Avg episode reward: [(0, '20.798')]\u001b[0m\n","\u001b[36m[2024-01-06 06:23:44,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3140.4, 300 sec: 3110.2). Total num frames: 3723264. Throughput: 0: 771.5. Samples: 929620. Policy #0 lag: (min: 0.0, avg: 0.4, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:23:44,312][00204] Avg episode reward: [(0, '21.409')]\u001b[0m\n","\u001b[36m[2024-01-06 06:23:49,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3140.3, 300 sec: 3110.2). Total num frames: 3735552. Throughput: 0: 768.3. Samples: 933348. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:23:49,318][00204] Avg episode reward: [(0, '22.091')]\u001b[0m\n","\u001b[36m[2024-01-06 06:23:54,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 3751936. Throughput: 0: 786.7. Samples: 937970. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:23:54,306][00204] Avg episode reward: [(0, '19.963')]\u001b[0m\n","\u001b[36m[2024-01-06 06:23:59,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 3768320. Throughput: 0: 787.8. Samples: 940878. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:23:59,312][00204] Avg episode reward: [(0, '19.714')]\u001b[0m\n","\u001b[36m[2024-01-06 06:24:04,304][00204] Fps is (10 sec: 3276.7, 60 sec: 3140.4, 300 sec: 3110.2). Total num frames: 3784704. Throughput: 0: 773.9. Samples: 945952. Policy #0 lag: (min: 0.0, avg: 0.6, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:24:04,307][00204] Avg episode reward: [(0, '20.109')]\u001b[0m\n","\u001b[36m[2024-01-06 06:24:09,305][00204] Fps is (10 sec: 2867.1, 60 sec: 3140.2, 300 sec: 3110.2). Total num frames: 3796992. Throughput: 0: 768.7. Samples: 949680. Policy #0 lag: (min: 0.0, avg: 0.6, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:24:09,310][00204] Avg episode reward: [(0, '20.003')]\u001b[0m\n","\u001b[36m[2024-01-06 06:24:14,304][00204] Fps is (10 sec: 2867.3, 60 sec: 3072.0, 300 sec: 3110.2). Total num frames: 3813376. Throughput: 0: 768.5. Samples: 951522. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:24:14,316][00204] Avg episode reward: [(0, '20.420')]\u001b[0m\n","\u001b[36m[2024-01-06 06:24:19,304][00204] Fps is (10 sec: 3686.6, 60 sec: 3140.4, 300 sec: 3110.2). Total num frames: 3833856. Throughput: 0: 788.0. Samples: 957236. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:24:19,306][00204] Avg episode reward: [(0, '19.863')]\u001b[0m\n","\u001b[36m[2024-01-06 06:24:24,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3208.5, 300 sec: 3110.2). Total num frames: 3850240. Throughput: 0: 777.6. Samples: 962450. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:24:24,312][00204] Avg episode reward: [(0, '20.633')]\u001b[0m\n","\u001b[36m[2024-01-06 06:24:29,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3140.3, 300 sec: 3096.3). Total num frames: 3858432. Throughput: 0: 769.4. Samples: 964242. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:24:29,307][00204] Avg episode reward: [(0, '19.516')]\u001b[0m\n","\u001b[36m[2024-01-06 06:24:34,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 3874816. Throughput: 0: 769.2. Samples: 967964. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:24:34,313][00204] Avg episode reward: [(0, '21.004')]\u001b[0m\n","\u001b[36m[2024-01-06 06:24:39,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3072.0, 300 sec: 3110.2). Total num frames: 3895296. Throughput: 0: 790.1. Samples: 973526. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:24:39,311][00204] Avg episode reward: [(0, '20.975')]\u001b[0m\n","\u001b[36m[2024-01-06 06:24:44,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3140.3, 300 sec: 3110.2). Total num frames: 3911680. Throughput: 0: 790.9. Samples: 976468. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:24:44,318][00204] Avg episode reward: [(0, '22.014')]\u001b[0m\n","\u001b[36m[2024-01-06 06:24:49,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3140.3, 300 sec: 3110.2). Total num frames: 3923968. Throughput: 0: 770.4. Samples: 980620. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:24:49,313][00204] Avg episode reward: [(0, '22.320')]\u001b[0m\n","\u001b[36m[2024-01-06 06:24:54,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3072.0, 300 sec: 3110.2). Total num frames: 3936256. Throughput: 0: 767.8. Samples: 984230. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:24:54,307][00204] Avg episode reward: [(0, '23.625')]\u001b[0m\n","\u001b[36m[2024-01-06 06:24:59,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3140.3, 300 sec: 3110.2). Total num frames: 3956736. Throughput: 0: 785.6. Samples: 986874. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:24:59,307][00204] Avg episode reward: [(0, '24.796')]\u001b[0m\n","\u001b[36m[2024-01-06 06:25:04,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3140.3, 300 sec: 3110.2). Total num frames: 3973120. Throughput: 0: 784.0. Samples: 992518. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:25:04,306][00204] Avg episode reward: [(0, '24.204')]\u001b[0m\n","\u001b[36m[2024-01-06 06:25:09,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3140.3, 300 sec: 3110.2). Total num frames: 3985408. Throughput: 0: 763.7. Samples: 996818. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:25:09,307][00204] Avg episode reward: [(0, '23.750')]\u001b[0m\n","\u001b[36m[2024-01-06 06:25:14,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3072.0, 300 sec: 3110.2). Total num frames: 3997696. Throughput: 0: 764.4. Samples: 998642. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:25:14,314][00204] Avg episode reward: [(0, '24.167')]\u001b[0m\n","\u001b[36m[2024-01-06 06:25:19,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3003.7, 300 sec: 3096.3). Total num frames: 4014080. Throughput: 0: 780.4. Samples: 1003082. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:25:19,312][00204] Avg episode reward: [(0, '23.078')]\u001b[0m\n","\u001b[36m[2024-01-06 06:25:24,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 4034560. Throughput: 0: 784.8. Samples: 1008840. Policy #0 lag: (min: 0.0, avg: 0.8, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:25:24,307][00204] Avg episode reward: [(0, '24.016')]\u001b[0m\n","\u001b[36m[2024-01-06 06:25:29,308][00204] Fps is (10 sec: 3275.4, 60 sec: 3140.0, 300 sec: 3096.3). Total num frames: 4046848. Throughput: 0: 773.2. Samples: 1011266. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:25:29,311][00204] Avg episode reward: [(0, '23.419')]\u001b[0m\n","\u001b[36m[2024-01-06 06:25:34,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 4059136. Throughput: 0: 764.0. Samples: 1015000. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:25:34,312][00204] Avg episode reward: [(0, '23.069')]\u001b[0m\n","\u001b[36m[2024-01-06 06:25:39,304][00204] Fps is (10 sec: 2868.4, 60 sec: 3003.7, 300 sec: 3096.3). Total num frames: 4075520. Throughput: 0: 782.6. Samples: 1019448. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:25:39,307][00204] Avg episode reward: [(0, '22.984')]\u001b[0m\n","\u001b[36m[2024-01-06 06:25:44,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 4096000. Throughput: 0: 790.0. Samples: 1022422. Policy #0 lag: (min: 0.0, avg: 0.7, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:25:44,315][00204] Avg episode reward: [(0, '24.973')]\u001b[0m\n","\u001b[36m[2024-01-06 06:25:49,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3140.3, 300 sec: 3110.2). Total num frames: 4112384. Throughput: 0: 782.3. Samples: 1027720. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:25:49,307][00204] Avg episode reward: [(0, '25.133')]\u001b[0m\n","\u001b[36m[2024-01-06 06:25:54,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3140.3, 300 sec: 3110.2). Total num frames: 4124672. Throughput: 0: 767.4. Samples: 1031352. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:25:54,307][00204] Avg episode reward: [(0, '24.460')]\u001b[0m\n","\u001b[36m[2024-01-06 06:25:59,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3003.7, 300 sec: 3096.3). Total num frames: 4136960. Throughput: 0: 767.1. Samples: 1033162. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:25:59,307][00204] Avg episode reward: [(0, '23.613')]\u001b[0m\n","\u001b[36m[2024-01-06 06:26:04,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 4157440. Throughput: 0: 783.3. Samples: 1038332. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:26:04,307][00204] Avg episode reward: [(0, '23.558')]\u001b[0m\n","\u001b[36m[2024-01-06 06:26:09,309][00204] Fps is (10 sec: 3684.6, 60 sec: 3140.0, 300 sec: 3110.1). Total num frames: 4173824. Throughput: 0: 780.1. Samples: 1043950. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:26:09,323][00204] Avg episode reward: [(0, '23.186')]\u001b[0m\n","\u001b[36m[2024-01-06 06:26:14,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3140.3, 300 sec: 3110.2). Total num frames: 4186112. Throughput: 0: 766.7. Samples: 1045762. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:26:14,309][00204] Avg episode reward: [(0, '24.964')]\u001b[0m\n","\u001b[36m[2024-01-06 06:26:19,304][00204] Fps is (10 sec: 2458.8, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 4198400. Throughput: 0: 764.7. Samples: 1049412. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:26:19,306][00204] Avg episode reward: [(0, '25.127')]\u001b[0m\n","\u001b[36m[2024-01-06 06:26:24,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3072.0, 300 sec: 3110.2). Total num frames: 4218880. Throughput: 0: 783.6. Samples: 1054712. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:26:24,306][00204] Avg episode reward: [(0, '24.390')]\u001b[0m\n","\u001b[36m[2024-01-06 06:26:29,308][00204] Fps is (10 sec: 3684.9, 60 sec: 3140.3, 300 sec: 3096.3). Total num frames: 4235264. Throughput: 0: 780.6. Samples: 1057550. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:26:29,314][00204] Avg episode reward: [(0, '24.149')]\u001b[0m\n","\u001b[36m[2024-01-06 06:26:34,305][00204] Fps is (10 sec: 2867.0, 60 sec: 3140.2, 300 sec: 3096.3). Total num frames: 4247552. Throughput: 0: 763.6. Samples: 1062082. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:26:34,310][00204] Avg episode reward: [(0, '24.191')]\u001b[0m\n","\u001b[36m[2024-01-06 06:26:39,305][00204] Fps is (10 sec: 2458.3, 60 sec: 3071.9, 300 sec: 3096.3). Total num frames: 4259840. Throughput: 0: 766.2. Samples: 1065830. Policy #0 lag: (min: 0.0, avg: 0.6, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:26:39,316][00204] Avg episode reward: [(0, '24.650')]\u001b[0m\n","\u001b[36m[2024-01-06 06:26:44,304][00204] Fps is (10 sec: 3277.0, 60 sec: 3072.0, 300 sec: 3110.2). Total num frames: 4280320. Throughput: 0: 777.3. Samples: 1068140. Policy #0 lag: (min: 0.0, avg: 0.6, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:26:44,313][00204] Avg episode reward: [(0, '25.376')]\u001b[0m\n","\u001b[36m[2024-01-06 06:26:49,304][00204] Fps is (10 sec: 3686.9, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 4296704. Throughput: 0: 787.9. Samples: 1073788. Policy #0 lag: (min: 0.0, avg: 0.6, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:26:49,315][00204] Avg episode reward: [(0, '23.618')]\u001b[0m\n","\u001b[36m[2024-01-06 06:26:54,308][00204] Fps is (10 sec: 3275.6, 60 sec: 3140.1, 300 sec: 3110.1). Total num frames: 4313088. Throughput: 0: 763.6. Samples: 1078312. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:26:54,317][00204] Avg episode reward: [(0, '23.450')]\u001b[0m\n","\u001b[36m[2024-01-06 06:26:59,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3140.3, 300 sec: 3110.2). Total num frames: 4325376. Throughput: 0: 763.5. Samples: 1080120. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:26:59,314][00204] Avg episode reward: [(0, '24.285')]\u001b[0m\n","\u001b[36m[2024-01-06 06:27:04,304][00204] Fps is (10 sec: 2868.2, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 4341760. Throughput: 0: 775.1. Samples: 1084290. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:27:04,311][00204] Avg episode reward: [(0, '23.194')]\u001b[0m\n","\u001b[36m[2024-01-06 06:27:09,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3072.2, 300 sec: 3096.3). Total num frames: 4358144. Throughput: 0: 785.3. Samples: 1090050. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:27:09,311][00204] Avg episode reward: [(0, '23.629')]\u001b[0m\n","\u001b[36m[2024-01-06 06:27:14,304][00204] Fps is (10 sec: 3276.7, 60 sec: 3140.3, 300 sec: 3110.2). Total num frames: 4374528. Throughput: 0: 783.2. Samples: 1092790. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:27:14,311][00204] Avg episode reward: [(0, '23.428')]\u001b[0m\n","\u001b[36m[2024-01-06 06:27:19,305][00204] Fps is (10 sec: 2867.0, 60 sec: 3140.2, 300 sec: 3110.2). Total num frames: 4386816. Throughput: 0: 764.4. Samples: 1096480. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:27:19,308][00204] Avg episode reward: [(0, '24.411')]\u001b[0m\n","\u001b[36m[2024-01-06 06:27:24,304][00204] Fps is (10 sec: 2867.3, 60 sec: 3072.0, 300 sec: 3110.2). Total num frames: 4403200. Throughput: 0: 770.2. Samples: 1100486. Policy #0 lag: (min: 0.0, avg: 0.7, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:27:24,307][00204] Avg episode reward: [(0, '23.687')]\u001b[0m\n","\u001b[36m[2024-01-06 06:27:29,304][00204] Fps is (10 sec: 3277.1, 60 sec: 3072.2, 300 sec: 3096.3). Total num frames: 4419584. Throughput: 0: 781.3. Samples: 1103300. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:27:29,308][00204] Avg episode reward: [(0, '22.808')]\u001b[0m\n","\u001b[36m[2024-01-06 06:27:34,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3140.3, 300 sec: 3096.3). Total num frames: 4435968. Throughput: 0: 787.8. Samples: 1109240. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:27:34,307][00204] Avg episode reward: [(0, '23.138')]\u001b[0m\n","\u001b[36m[2024-01-06 06:27:39,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3140.3, 300 sec: 3096.3). Total num frames: 4448256. Throughput: 0: 769.3. Samples: 1112928. Policy #0 lag: (min: 0.0, avg: 0.6, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:27:39,308][00204] Avg episode reward: [(0, '23.832')]\u001b[0m\n","\u001b[36m[2024-01-06 06:27:44,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3072.0, 300 sec: 3110.2). Total num frames: 4464640. Throughput: 0: 770.8. Samples: 1114804. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:27:44,307][00204] Avg episode reward: [(0, '24.230')]\u001b[0m\n","\u001b[36m[2024-01-06 06:27:49,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3140.3, 300 sec: 3110.2). Total num frames: 4485120. Throughput: 0: 792.7. Samples: 1119960. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:27:49,308][00204] Avg episode reward: [(0, '24.744')]\u001b[0m\n","\u001b[36m[2024-01-06 06:27:54,305][00204] Fps is (10 sec: 3686.2, 60 sec: 3140.4, 300 sec: 3110.2). Total num frames: 4501504. Throughput: 0: 795.0. Samples: 1125824. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:27:54,310][00204] Avg episode reward: [(0, '24.816')]\u001b[0m\n","\u001b[36m[2024-01-06 06:27:59,305][00204] Fps is (10 sec: 2867.0, 60 sec: 3140.2, 300 sec: 3110.2). Total num frames: 4513792. Throughput: 0: 775.7. Samples: 1127698. Policy #0 lag: (min: 0.0, avg: 0.6, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:27:59,310][00204] Avg episode reward: [(0, '25.193')]\u001b[0m\n","\u001b[36m[2024-01-06 06:28:04,304][00204] Fps is (10 sec: 2457.7, 60 sec: 3072.0, 300 sec: 3110.2). Total num frames: 4526080. Throughput: 0: 774.6. Samples: 1131336. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:28:04,307][00204] Avg episode reward: [(0, '25.856')]\u001b[0m\n","\u001b[36m[2024-01-06 06:28:09,304][00204] Fps is (10 sec: 2867.4, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 4542464. Throughput: 0: 788.7. Samples: 1135976. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:28:09,307][00204] Avg episode reward: [(0, '25.050')]\u001b[0m\n","\u001b[36m[2024-01-06 06:28:14,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3140.3, 300 sec: 3110.2). Total num frames: 4562944. Throughput: 0: 788.9. Samples: 1138800. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:28:14,307][00204] Avg episode reward: [(0, '24.272')]\u001b[0m\n","\u001b[36m[2024-01-06 06:28:19,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3140.3, 300 sec: 3110.2). Total num frames: 4575232. Throughput: 0: 765.0. Samples: 1143664. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:28:19,307][00204] Avg episode reward: [(0, '23.691')]\u001b[0m\n","\u001b[36m[2024-01-06 06:28:24,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3072.0, 300 sec: 3110.2). Total num frames: 4587520. Throughput: 0: 758.5. Samples: 1147062. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:28:24,310][00204] Avg episode reward: [(0, '22.361')]\u001b[0m\n","\u001b[36m[2024-01-06 06:28:29,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3003.7, 300 sec: 3082.4). Total num frames: 4599808. Throughput: 0: 755.1. Samples: 1148782. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:28:29,316][00204] Avg episode reward: [(0, '21.990')]\u001b[0m\n","\u001b[36m[2024-01-06 06:28:34,309][00204] Fps is (10 sec: 3275.3, 60 sec: 3071.8, 300 sec: 3082.4). Total num frames: 4620288. Throughput: 0: 763.8. Samples: 1154336. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:28:34,311][00204] Avg episode reward: [(0, '21.667')]\u001b[0m\n","\u001b[36m[2024-01-06 06:28:39,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3140.3, 300 sec: 3096.3). Total num frames: 4636672. Throughput: 0: 745.0. Samples: 1159350. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:28:39,309][00204] Avg episode reward: [(0, '21.162')]\u001b[0m\n","\u001b[36m[2024-01-06 06:28:44,304][00204] Fps is (10 sec: 2868.5, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 4648960. Throughput: 0: 743.8. Samples: 1161170. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:28:44,311][00204] Avg episode reward: [(0, '21.213')]\u001b[0m\n","\u001b[36m[2024-01-06 06:28:49,304][00204] Fps is (10 sec: 2457.6, 60 sec: 2935.5, 300 sec: 3082.4). Total num frames: 4661248. Throughput: 0: 739.5. Samples: 1164614. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:28:49,307][00204] Avg episode reward: [(0, '20.666')]\u001b[0m\n","\u001b[36m[2024-01-06 06:28:54,304][00204] Fps is (10 sec: 2867.2, 60 sec: 2935.5, 300 sec: 3082.4). Total num frames: 4677632. Throughput: 0: 752.9. Samples: 1169858. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:28:54,311][00204] Avg episode reward: [(0, '21.075')]\u001b[0m\n","\u001b[36m[2024-01-06 06:28:59,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3003.8, 300 sec: 3082.4). Total num frames: 4694016. Throughput: 0: 749.6. Samples: 1172534. Policy #0 lag: (min: 0.0, avg: 0.6, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:28:59,314][00204] Avg episode reward: [(0, '21.279')]\u001b[0m\n","\u001b[36m[2024-01-06 06:29:04,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3003.7, 300 sec: 3082.4). Total num frames: 4706304. Throughput: 0: 733.0. Samples: 1176648. Policy #0 lag: (min: 0.0, avg: 0.6, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:29:04,308][00204] Avg episode reward: [(0, '20.553')]\u001b[0m\n","\u001b[36m[2024-01-06 06:29:09,304][00204] Fps is (10 sec: 2457.5, 60 sec: 2935.5, 300 sec: 3068.5). Total num frames: 4718592. Throughput: 0: 738.5. Samples: 1180296. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:29:09,316][00204] Avg episode reward: [(0, '20.485')]\u001b[0m\n","\u001b[36m[2024-01-06 06:29:14,304][00204] Fps is (10 sec: 3276.8, 60 sec: 2935.5, 300 sec: 3068.5). Total num frames: 4739072. Throughput: 0: 760.6. Samples: 1183010. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:29:14,307][00204] Avg episode reward: [(0, '20.598')]\u001b[0m\n","\u001b[36m[2024-01-06 06:29:19,304][00204] Fps is (10 sec: 4096.2, 60 sec: 3072.0, 300 sec: 3082.4). Total num frames: 4759552. Throughput: 0: 766.5. Samples: 1188824. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:29:19,316][00204] Avg episode reward: [(0, '21.973')]\u001b[0m\n","\u001b[36m[2024-01-06 06:29:24,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3072.0, 300 sec: 3096.3). Total num frames: 4771840. Throughput: 0: 749.4. Samples: 1193072. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:29:24,309][00204] Avg episode reward: [(0, '22.657')]\u001b[0m\n","\u001b[36m[2024-01-06 06:29:29,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3072.0, 300 sec: 3082.4). Total num frames: 4784128. Throughput: 0: 748.3. Samples: 1194844. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:29:29,313][00204] Avg episode reward: [(0, '23.156')]\u001b[0m\n","\u001b[36m[2024-01-06 06:29:34,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3004.0, 300 sec: 3068.5). Total num frames: 4800512. Throughput: 0: 768.4. Samples: 1199190. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:29:34,307][00204] Avg episode reward: [(0, '22.691')]\u001b[0m\n","\u001b[36m[2024-01-06 06:29:39,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3072.0, 300 sec: 3082.4). Total num frames: 4820992. Throughput: 0: 778.5. Samples: 1204890. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:29:39,307][00204] Avg episode reward: [(0, '23.063')]\u001b[0m\n","\u001b[36m[2024-01-06 06:29:44,304][00204] Fps is (10 sec: 3276.8, 60 sec: 3072.0, 300 sec: 3082.4). Total num frames: 4833280. Throughput: 0: 776.0. Samples: 1207452. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:29:44,313][00204] Avg episode reward: [(0, '22.829')]\u001b[0m\n","\u001b[36m[2024-01-06 06:29:49,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3072.0, 300 sec: 3082.4). Total num frames: 4845568. Throughput: 0: 766.0. Samples: 1211120. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:29:49,309][00204] Avg episode reward: [(0, '22.074')]\u001b[0m\n","\u001b[36m[2024-01-06 06:29:54,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3072.0, 300 sec: 3068.5). Total num frames: 4861952. Throughput: 0: 781.3. Samples: 1215452. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:29:54,316][00204] Avg episode reward: [(0, '21.617')]\u001b[0m\n","\u001b[36m[2024-01-06 06:29:59,304][00204] Fps is (10 sec: 3276.7, 60 sec: 3072.0, 300 sec: 3068.5). Total num frames: 4878336. Throughput: 0: 783.4. Samples: 1218262. Policy #0 lag: (min: 0.0, avg: 0.5, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:29:59,308][00204] Avg episode reward: [(0, '22.101')]\u001b[0m\n","\u001b[36m[2024-01-06 06:30:04,305][00204] Fps is (10 sec: 3276.8, 60 sec: 3140.3, 300 sec: 3082.4). Total num frames: 4894720. Throughput: 0: 775.8. Samples: 1223736. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:30:04,308][00204] Avg episode reward: [(0, '22.618')]\u001b[0m\n","\u001b[36m[2024-01-06 06:30:09,308][00204] Fps is (10 sec: 2866.2, 60 sec: 3140.1, 300 sec: 3082.4). Total num frames: 4907008. Throughput: 0: 765.1. Samples: 1227506. Policy #0 lag: (min: 0.0, avg: 0.4, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:30:09,312][00204] Avg episode reward: [(0, '23.484')]\u001b[0m\n","\u001b[36m[2024-01-06 06:30:14,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3072.0, 300 sec: 3082.4). Total num frames: 4923392. Throughput: 0: 766.4. Samples: 1229334. Policy #0 lag: (min: 0.0, avg: 0.4, max: 1.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:30:14,307][00204] Avg episode reward: [(0, '24.168')]\u001b[0m\n","\u001b[36m[2024-01-06 06:30:19,305][00204] Fps is (10 sec: 3277.8, 60 sec: 3003.7, 300 sec: 3068.5). Total num frames: 4939776. Throughput: 0: 787.4. Samples: 1234622. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:30:19,315][00204] Avg episode reward: [(0, '24.101')]\u001b[0m\n","\u001b[36m[2024-01-06 06:30:24,304][00204] Fps is (10 sec: 3686.4, 60 sec: 3140.3, 300 sec: 3096.3). Total num frames: 4960256. Throughput: 0: 786.7. Samples: 1240290. Policy #0 lag: (min: 0.0, avg: 0.4, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:30:24,309][00204] Avg episode reward: [(0, '24.227')]\u001b[0m\n","\u001b[36m[2024-01-06 06:30:29,304][00204] Fps is (10 sec: 3277.0, 60 sec: 3140.3, 300 sec: 3096.3). Total num frames: 4972544. Throughput: 0: 770.0. Samples: 1242100. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:30:29,311][00204] Avg episode reward: [(0, '24.367')]\u001b[0m\n","\u001b[36m[2024-01-06 06:30:34,304][00204] Fps is (10 sec: 2457.6, 60 sec: 3072.0, 300 sec: 3082.4). Total num frames: 4984832. Throughput: 0: 769.7. Samples: 1245758. Policy #0 lag: (min: 0.0, avg: 0.5, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:30:34,307][00204] Avg episode reward: [(0, '23.003')]\u001b[0m\n","\u001b[36m[2024-01-06 06:30:39,304][00204] Fps is (10 sec: 2867.2, 60 sec: 3003.7, 300 sec: 3068.5). Total num frames: 5001216. Throughput: 0: 788.2. Samples: 1250920. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)\u001b[0m\n","\u001b[36m[2024-01-06 06:30:39,307][00204] Avg episode reward: [(0, '21.630')]\u001b[0m\n","\u001b[36m[2024-01-06 06:30:39,432][00204] Component Batcher_0 stopped!\u001b[0m\n","\u001b[36m[2024-01-06 06:30:39,486][00204] Component InferenceWorker_p0-w0 stopped!\u001b[0m\n","\u001b[36m[2024-01-06 06:30:39,523][00204] Component RolloutWorker_w3 stopped!\u001b[0m\n","\u001b[36m[2024-01-06 06:30:39,535][00204] Component RolloutWorker_w4 stopped!\u001b[0m\n","\u001b[36m[2024-01-06 06:30:39,552][00204] Component RolloutWorker_w7 stopped!\u001b[0m\n","\u001b[36m[2024-01-06 06:30:39,554][00204] Component RolloutWorker_w5 stopped!\u001b[0m\n","\u001b[36m[2024-01-06 06:30:39,563][00204] Component RolloutWorker_w1 stopped!\u001b[0m\n","\u001b[36m[2024-01-06 06:30:39,588][00204] Component RolloutWorker_w2 stopped!\u001b[0m\n","\u001b[36m[2024-01-06 06:30:39,590][00204] Component RolloutWorker_w6 stopped!\u001b[0m\n","\u001b[36m[2024-01-06 06:30:39,624][00204] Component RolloutWorker_w0 stopped!\u001b[0m\n","\u001b[36m[2024-01-06 06:30:39,827][00204] Component LearnerWorker_p0 stopped!\u001b[0m\n","\u001b[36m[2024-01-06 06:30:39,834][00204] Waiting for process learner_proc0 to stop...\u001b[0m\n","\u001b[36m[2024-01-06 06:30:41,518][00204] Waiting for process inference_proc0-0 to join...\u001b[0m\n","\u001b[36m[2024-01-06 06:30:41,647][00204] Waiting for process rollout_proc0 to join...\u001b[0m\n","\u001b[36m[2024-01-06 06:30:42,796][00204] Waiting for process rollout_proc1 to join...\u001b[0m\n","\u001b[36m[2024-01-06 06:30:42,893][00204] Waiting for process rollout_proc2 to join...\u001b[0m\n","\u001b[36m[2024-01-06 06:30:42,896][00204] Waiting for process rollout_proc3 to join...\u001b[0m\n","\u001b[36m[2024-01-06 06:30:42,902][00204] Waiting for process rollout_proc4 to join...\u001b[0m\n","\u001b[36m[2024-01-06 06:30:42,904][00204] Waiting for process rollout_proc5 to join...\u001b[0m\n","\u001b[36m[2024-01-06 06:30:42,906][00204] Waiting for process rollout_proc6 to join...\u001b[0m\n","\u001b[36m[2024-01-06 06:30:42,908][00204] Waiting for process rollout_proc7 to join...\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:30:42,911][00204] Batcher 0 profile tree view:\n","batching: 34.7533, releasing_batches: 0.0337\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:30:42,912][00204] InferenceWorker_p0-w0 profile tree view:\n","wait_policy: 0.0000\n","  wait_policy_total: 833.9550\n","update_model: 10.4992\n","  weight_update: 0.0013\n","one_step: 0.0083\n","  handle_policy_step: 748.0737\n","    deserialize: 20.1037, stack: 4.1395, obs_to_device_normalize: 153.9252, forward: 384.3849, send_messages: 35.3797\n","    prepare_outputs: 112.4000\n","      to_cpu: 69.3474\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:30:42,914][00204] Learner 0 profile tree view:\n","misc: 0.0074, prepare_batch: 19.7144\n","train: 93.0088\n","  epoch_init: 0.0078, minibatch_init: 0.0327, losses_postprocess: 0.5744, kl_divergence: 0.7745, after_optimizer: 40.5753\n","  calculate_losses: 31.7974\n","    losses_init: 0.0054, forward_head: 2.4329, bptt_initial: 20.2768, tail: 1.4481, advantages_returns: 0.3701, losses: 3.9662\n","    bptt: 2.8848\n","      bptt_forward_core: 2.7795\n","  update: 18.1280\n","    clip: 1.8675\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:30:42,915][00204] RolloutWorker_w0 profile tree view:\n","wait_for_trajectories: 0.5212, enqueue_policy_requests: 256.0319, env_step: 1214.4615, overhead: 35.4546, complete_rollouts: 10.2947\n","save_policy_outputs: 32.9519\n","  split_output_tensors: 15.4434\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:30:42,917][00204] RolloutWorker_w7 profile tree view:\n","wait_for_trajectories: 0.4380, enqueue_policy_requests: 257.0276, env_step: 1212.9260, overhead: 35.3100, complete_rollouts: 10.0706\n","save_policy_outputs: 32.4075\n","  split_output_tensors: 14.7930\u001b[0m\n","\u001b[36m[2024-01-06 06:30:42,918][00204] Loop Runner_EvtLoop terminating...\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:30:42,920][00204] Runner profile tree view:\n","main_loop: 1674.3352\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:30:42,921][00204] Collected {0: 5005312}, FPS: 2989.4\u001b[0m\n"]}],"source":["## Start the training, this should take around 15 minutes\n","register_vizdoom_components()\n","\n","# The scenario we train on today is health gathering\n","# other scenarios include \"doom_basic\", \"doom_two_colors_easy\", \"doom_dm\", \"doom_dwango5\", \"doom_my_way_home\", \"doom_deadly_corridor\", \"doom_defend_the_center\", \"doom_defend_the_line\"\n","env = \"doom_health_gathering_supreme\"\n","cfg = parse_vizdoom_cfg(argv=[f\"--env={env}\", \"--num_workers=8\", \"--num_envs_per_worker=4\", \"--train_for_env_steps=5000000\"])\n","\n","status = run_rl(cfg)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":86899,"status":"ok","timestamp":1704522740270,"user":{"displayName":"Weiming Li","userId":"10689989110268100587"},"user_tz":-480},"id":"voOzpQYgVvM7","outputId":"04523169-c304-4eca-ba40-86e05ef7097c"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[33m[2024-01-06 06:30:53,323][00204] Loading existing experiment configuration from /content/train_dir/default_experiment/config.json\u001b[0m\n","\u001b[36m[2024-01-06 06:30:53,326][00204] Overriding arg 'num_workers' with value 1 passed from command line\u001b[0m\n","\u001b[36m[2024-01-06 06:30:53,328][00204] Adding new argument 'no_render'=True that is not in the saved config file!\u001b[0m\n","\u001b[36m[2024-01-06 06:30:53,330][00204] Adding new argument 'save_video'=True that is not in the saved config file!\u001b[0m\n","\u001b[36m[2024-01-06 06:30:53,332][00204] Adding new argument 'video_frames'=1000000000.0 that is not in the saved config file!\u001b[0m\n","\u001b[36m[2024-01-06 06:30:53,334][00204] Adding new argument 'video_name'=None that is not in the saved config file!\u001b[0m\n","\u001b[36m[2024-01-06 06:30:53,335][00204] Adding new argument 'max_num_frames'=1000000000.0 that is not in the saved config file!\u001b[0m\n","\u001b[36m[2024-01-06 06:30:53,336][00204] Adding new argument 'max_num_episodes'=10 that is not in the saved config file!\u001b[0m\n","\u001b[36m[2024-01-06 06:30:53,338][00204] Adding new argument 'push_to_hub'=False that is not in the saved config file!\u001b[0m\n","\u001b[36m[2024-01-06 06:30:53,339][00204] Adding new argument 'hf_repository'=None that is not in the saved config file!\u001b[0m\n","\u001b[36m[2024-01-06 06:30:53,340][00204] Adding new argument 'policy_index'=0 that is not in the saved config file!\u001b[0m\n","\u001b[36m[2024-01-06 06:30:53,341][00204] Adding new argument 'eval_deterministic'=False that is not in the saved config file!\u001b[0m\n","\u001b[36m[2024-01-06 06:30:53,342][00204] Using frameskip 1 and render_action_repeat=4 for evaluation\u001b[0m\n","\u001b[36m[2024-01-06 06:30:53,362][00204] Doom resolution: 160x120, resize resolution: (128, 72)\u001b[0m\n","\u001b[36m[2024-01-06 06:30:53,364][00204] RunningMeanStd input shape: (3, 72, 128)\u001b[0m\n","\u001b[36m[2024-01-06 06:30:53,367][00204] RunningMeanStd input shape: (1,)\u001b[0m\n","\u001b[36m[2024-01-06 06:30:53,391][00204] ConvEncoder: input_channels=3\u001b[0m\n","\u001b[36m[2024-01-06 06:30:53,512][00204] Conv encoder output size: 512\u001b[0m\n","\u001b[36m[2024-01-06 06:30:53,514][00204] Policy head output size: 512\u001b[0m\n","\u001b[33m[2024-01-06 06:30:55,071][00204] Loading state from checkpoint /content/train_dir/default_experiment/checkpoint_p0/checkpoint_000001222_5005312.pth...\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:30:57,404][00204] Avg episode rewards: #0: 17.890, true rewards: #0: 8.890\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:30:57,407][00204] Avg episode reward: 17.890, avg true_objective: 8.890\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:31:00,572][00204] Avg episode rewards: #0: 37.444, true rewards: #0: 14.945\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:31:00,574][00204] Avg episode reward: 37.444, avg true_objective: 14.945\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:31:01,660][00204] Avg episode rewards: #0: 29.963, true rewards: #0: 12.630\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:31:01,662][00204] Avg episode reward: 29.963, avg true_objective: 12.630\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:31:02,677][00204] Avg episode rewards: #0: 26.392, true rewards: #0: 11.393\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:31:02,679][00204] Avg episode reward: 26.392, avg true_objective: 11.393\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:31:05,397][00204] Avg episode rewards: #0: 31.714, true rewards: #0: 13.314\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:31:05,399][00204] Avg episode reward: 31.714, avg true_objective: 13.314\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:31:06,198][00204] Avg episode rewards: #0: 28.225, true rewards: #0: 12.058\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:31:06,200][00204] Avg episode reward: 28.225, avg true_objective: 12.058\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:31:07,012][00204] Avg episode rewards: #0: 25.918, true rewards: #0: 11.204\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:31:07,013][00204] Avg episode reward: 25.918, avg true_objective: 11.204\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:31:08,265][00204] Avg episode rewards: #0: 25.379, true rewards: #0: 11.004\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:31:08,268][00204] Avg episode reward: 25.379, avg true_objective: 11.004\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:31:09,363][00204] Avg episode rewards: #0: 23.941, true rewards: #0: 10.608\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:31:09,366][00204] Avg episode reward: 23.941, avg true_objective: 10.608\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:31:11,352][00204] Avg episode rewards: #0: 23.835, true rewards: #0: 10.635\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:31:11,353][00204] Avg episode reward: 23.835, avg true_objective: 10.635\u001b[0m\n"]}],"source":["from sample_factory.enjoy import enjoy\n","cfg = parse_vizdoom_cfg(argv=[f\"--env={env}\", \"--num_workers=1\", \"--save_video\", \"--no_render\", \"--max_num_episodes=10\"], evaluation=True)\n","status = enjoy(cfg)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":67816,"status":"ok","timestamp":1704522815262,"user":{"displayName":"Weiming Li","userId":"10689989110268100587"},"user_tz":-480},"id":"Bc6vxihaVzFI"},"outputs":[],"source":["from base64 import b64encode\n","from IPython.display import HTML\n","\n","mp4 = open('/content/train_dir/default_experiment/replay.mp4','rb').read()\n","data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","HTML(\"\"\"\n","\u003cvideo width=640 controls\u003e\n","      \u003csource src=\"%s\" type=\"video/mp4\"\u003e\n","\u003c/video\u003e\n","\"\"\" % data_url)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":162},"executionInfo":{"elapsed":722,"status":"ok","timestamp":1704522999956,"user":{"displayName":"Weiming Li","userId":"10689989110268100587"},"user_tz":-480},"id":"ZycV6clLX5TV","outputId":"ac5314f3-f821-4faa-e7b7-e64415989472"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f759c41120ad42a7b918b357bff0ba93","version_major":2,"version_minor":0},"text/plain":["VBox(children=(HTML(value='\u003ccenter\u003e \u003cimg\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"]},"metadata":{},"output_type":"display_data"}],"source":["from huggingface_hub import notebook_login\n","notebook_login()\n","!git config --global credential.helper store\n","\n","# !huggingface-cli login --token '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'"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":127565,"status":"ok","timestamp":1704523139137,"user":{"displayName":"Weiming Li","userId":"10689989110268100587"},"user_tz":-480},"id":"P7O7zYzrX8sl","outputId":"f2f223cf-02a2-4665-a28d-ad3f3768f237"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[33m[2024-01-06 06:36:51,286][00204] Loading existing experiment configuration from /content/train_dir/default_experiment/config.json\u001b[0m\n","\u001b[36m[2024-01-06 06:36:51,288][00204] Overriding arg 'num_workers' with value 1 passed from command line\u001b[0m\n","\u001b[36m[2024-01-06 06:36:51,290][00204] Adding new argument 'no_render'=True that is not in the saved config file!\u001b[0m\n","\u001b[36m[2024-01-06 06:36:51,292][00204] Adding new argument 'save_video'=True that is not in the saved config file!\u001b[0m\n","\u001b[36m[2024-01-06 06:36:51,295][00204] Adding new argument 'video_frames'=1000000000.0 that is not in the saved config file!\u001b[0m\n","\u001b[36m[2024-01-06 06:36:51,296][00204] Adding new argument 'video_name'=None that is not in the saved config file!\u001b[0m\n","\u001b[36m[2024-01-06 06:36:51,299][00204] Adding new argument 'max_num_frames'=100000 that is not in the saved config file!\u001b[0m\n","\u001b[36m[2024-01-06 06:36:51,300][00204] Adding new argument 'max_num_episodes'=10 that is not in the saved config file!\u001b[0m\n","\u001b[36m[2024-01-06 06:36:51,301][00204] Adding new argument 'push_to_hub'=True that is not in the saved config file!\u001b[0m\n","\u001b[36m[2024-01-06 06:36:51,302][00204] Adding new argument 'hf_repository'='Weiming1122/rl_course_vizdoom_health_gathering_supreme' that is not in the saved config file!\u001b[0m\n","\u001b[36m[2024-01-06 06:36:51,303][00204] Adding new argument 'policy_index'=0 that is not in the saved config file!\u001b[0m\n","\u001b[36m[2024-01-06 06:36:51,305][00204] Adding new argument 'eval_deterministic'=False that is not in the saved config file!\u001b[0m\n","\u001b[36m[2024-01-06 06:36:51,306][00204] Using frameskip 1 and render_action_repeat=4 for evaluation\u001b[0m\n","\u001b[36m[2024-01-06 06:36:51,323][00204] RunningMeanStd input shape: (3, 72, 128)\u001b[0m\n","\u001b[36m[2024-01-06 06:36:51,325][00204] RunningMeanStd input shape: (1,)\u001b[0m\n","\u001b[36m[2024-01-06 06:36:51,340][00204] ConvEncoder: input_channels=3\u001b[0m\n","\u001b[36m[2024-01-06 06:36:51,376][00204] Conv encoder output size: 512\u001b[0m\n","\u001b[36m[2024-01-06 06:36:51,377][00204] Policy head output size: 512\u001b[0m\n","\u001b[33m[2024-01-06 06:36:51,399][00204] Loading state from checkpoint /content/train_dir/default_experiment/checkpoint_p0/checkpoint_000001222_5005312.pth...\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:36:53,302][00204] Avg episode rewards: #0: 19.320, true rewards: #0: 8.320\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:36:53,305][00204] Avg episode reward: 19.320, avg true_objective: 8.320\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:36:54,157][00204] Avg episode rewards: #0: 12.400, true rewards: #0: 6.400\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:36:54,159][00204] Avg episode reward: 12.400, avg true_objective: 6.400\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:36:56,471][00204] Avg episode rewards: #0: 23.710, true rewards: #0: 9.710\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:36:56,472][00204] Avg episode reward: 23.710, avg true_objective: 9.710\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:36:58,553][00204] Avg episode rewards: #0: 25.952, true rewards: #0: 11.202\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:36:58,554][00204] Avg episode reward: 25.952, avg true_objective: 11.202\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:37:00,718][00204] Avg episode rewards: #0: 28.814, true rewards: #0: 12.214\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:37:00,721][00204] Avg episode reward: 28.814, avg true_objective: 12.214\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:37:01,481][00204] Avg episode rewards: #0: 26.032, true rewards: #0: 11.032\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:37:01,483][00204] Avg episode reward: 26.032, avg true_objective: 11.032\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:37:02,935][00204] Avg episode rewards: #0: 25.536, true rewards: #0: 10.964\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:37:02,937][00204] Avg episode reward: 25.536, avg true_objective: 10.964\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:37:03,567][00204] Avg episode rewards: #0: 23.029, true rewards: #0: 10.154\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:37:03,569][00204] Avg episode reward: 23.029, avg true_objective: 10.154\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:37:06,986][00204] Avg episode rewards: #0: 26.692, true rewards: #0: 11.359\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:37:06,989][00204] Avg episode reward: 26.692, avg true_objective: 11.359\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:37:08,752][00204] Avg episode rewards: #0: 26.407, true rewards: #0: 11.407\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:37:08,754][00204] Avg episode reward: 26.407, avg true_objective: 11.407\u001b[0m\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3bbc2cd1ae5f4e99af79a8a6419711f7","version_major":2,"version_minor":0},"text/plain":["events.out.tfevents.1704520964.5f74293c5f3a:   0%|          | 0.00/702k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"695017806acf4c1585c04b271225b765","version_major":2,"version_minor":0},"text/plain":["best_000001105_4526080_reward_25.856.pth:   0%|          | 0.00/34.9M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3a3c112bc0b04fe988276e6fbfb3cc6c","version_major":2,"version_minor":0},"text/plain":["Upload 3 LFS files:   0%|          | 0/3 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e9b1d6598a54165924dffd19162adb2","version_major":2,"version_minor":0},"text/plain":["checkpoint_000001222_5005312.pth:   0%|          | 0.00/34.9M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9dcadc46a9f34d8c9b67472e1aac4f1e","version_major":2,"version_minor":0},"text/plain":["checkpoint_000001135_4648960.pth:   0%|          | 0.00/34.9M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0fb62a9d990144d8808b049ce7bb25d9","version_major":2,"version_minor":0},"text/plain":["replay.mp4:   0%|          | 0.00/21.7M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[37m\u001b[1m[2024-01-06 06:38:58,362][00204] The model has been pushed to https://huggingface.co/Weiming1122/rl_course_vizdoom_health_gathering_supreme\u001b[0m\n"]}],"source":["from sample_factory.enjoy import enjoy\n","\n","hf_username = \"Weiming1122\" # insert your HuggingFace username here\n","\n","cfg = parse_vizdoom_cfg(argv=[f\"--env={env}\", \"--num_workers=1\", \"--save_video\", \"--no_render\", \"--max_num_episodes=10\", \"--max_num_frames=100000\", \"--push_to_hub\", f\"--hf_repository={hf_username}/rl_course_vizdoom_health_gathering_supreme\"], evaluation=True)\n","status = enjoy(cfg)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29292,"status":"ok","timestamp":1704523191586,"user":{"displayName":"Weiming Li","userId":"10689989110268100587"},"user_tz":-480},"id":"eA4IAsWMYFEm","outputId":"d907a205-f7ee-4867-c329-cfce5d59d5b9"},"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n","For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n","  warnings.warn(warning_message, FutureWarning)\n","Cloning https://huggingface.co/edbeeching/doom_health_gathering_supreme_2222 into local empty directory.\n","Download file checkpoint_p0/best_000466273_3819708416_reward_63.056.pth:   0% 100k/39.3M [00:01\u003c09:47, 70.0kB/s]\n","Download file checkpoint_p0/best_000466273_3819708416_reward_63.056.pth:   3% 1.11M/39.3M [00:02\u003c01:01, 654kB/s]\n","Download file replay.mp4:   1% 24.4k/4.07M [00:01\u003c04:04, 17.4kB/s]\u001b[A\n","\n","Download file .summary/0/events.out.tfevents.1666554178.r12i0n7:   0% 31.4k/8.77M [00:00\u003c?, ?B/s]\u001b[A\u001b[A\n","\n","\n","Download file checkpoint_p0/checkpoint_000538763_4413546496.pth:   0% 32.0k/39.3M [00:00\u003c?, ?B/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Download file checkpoint_p0/best_000466273_3819708416_reward_63.056.pth:  20% 7.86M/39.3M [00:03\u003c00:09, 3.58MB/s]\n","\n","Download file .summary/0/events.out.tfevents.1666554178.r12i0n7:   3% 282k/8.77M [00:01\u003c00:34, 256kB/s]\u001b[A\u001b[A\n","\n","\n","Download file checkpoint_p0/checkpoint_000538763_4413546496.pth:   1% 285k/39.3M [00:01\u003c02:38, 258kB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Download file checkpoint_p0/checkpoint_000539850_4422451200.pth:   1% 236k/39.3M [00:01\u003c03:17, 208kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","Download file replay.mp4:  11% 473k/4.07M [00:02\u003c00:13, 277kB/s]  \u001b[A\n","\n","\n","Download file checkpoint_p0/checkpoint_000538763_4413546496.pth:   8% 3.16M/39.3M [00:02\u003c00:20, 1.88MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Download file checkpoint_p0/checkpoint_000539850_4422451200.pth:   7% 2.73M/39.3M [00:02\u003c00:23, 1.62MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Download file checkpoint_p0/best_000466273_3819708416_reward_63.056.pth:  33% 13.0M/39.3M [00:04\u003c00:06, 4.28MB/s]\n","Download file replay.mp4:  91% 3.71M/4.07M [00:03\u003c00:00, 1.70MB/s]\u001b[A\n","\n","\n","\n","\n","Clean file replay.mp4:   0% 1.00k/4.07M [00:00\u003c?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Download file checkpoint_p0/best_000466273_3819708416_reward_63.056.pth:  46% 18.0M/39.3M [00:05\u003c00:04, 4.61MB/s]\n","\n","\n","\n","Download file checkpoint_p0/checkpoint_000539850_4422451200.pth:  20% 7.73M/39.3M [00:03\u003c00:10, 3.26MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Download file checkpoint_p0/checkpoint_000538763_4413546496.pth:  21% 8.16M/39.3M [00:03\u003c00:09, 3.40MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Clean file .summary/0/events.out.tfevents.1666554178.r12i0n7:   0% 1.00k/8.77M [00:00\u003c?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Download file checkpoint_p0/checkpoint_000539850_4422451200.pth:  32% 12.5M/39.3M [00:04\u003c00:07, 3.96MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Clean file .summary/0/events.out.tfevents.1666554178.r12i0n7:  45% 3.94M/8.77M [00:01\u003c00:01, 4.12MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Download file checkpoint_p0/best_000466273_3819708416_reward_63.056.pth:  71% 27.8M/39.3M [00:07\u003c00:02, 4.90MB/s]\n","\n","\n","Download file checkpoint_p0/checkpoint_000538763_4413546496.pth:  46% 18.0M/39.3M [00:05\u003c00:05, 4.47MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Download file checkpoint_p0/best_000466273_3819708416_reward_63.056.pth:  83% 32.7M/39.3M [00:08\u003c00:01, 4.99MB/s]\n","\n","\n","Download file checkpoint_p0/checkpoint_000538763_4413546496.pth:  58% 22.9M/39.3M [00:06\u003c00:03, 4.72MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Download file checkpoint_p0/checkpoint_000539850_4422451200.pth:  57% 22.5M/39.3M [00:06\u003c00:03, 4.68MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Download file checkpoint_p0/checkpoint_000538763_4413546496.pth:  69% 26.9M/39.3M [00:07\u003c00:02, 4.54MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Download file checkpoint_p0/best_000466273_3819708416_reward_63.056.pth:  94% 36.8M/39.3M [00:09\u003c00:00, 4.75MB/s]\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/best_000466273_3819708416_reward_63.056.pth:   0% 1.00k/39.3M [00:00\u003c?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/best_000466273_3819708416_reward_63.056.pth:   4% 1.47M/39.3M [00:01\u003c00:25, 1.54MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Download file checkpoint_p0/checkpoint_000538763_4413546496.pth:  80% 31.3M/39.3M [00:08\u003c00:01, 4.55MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Download file checkpoint_p0/checkpoint_000539850_4422451200.pth:  79% 30.9M/39.3M [00:08\u003c00:01, 4.55MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Download file checkpoint_p0/checkpoint_000539850_4422451200.pth:  91% 35.8M/39.3M [00:09\u003c00:00, 4.71MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/best_000466273_3819708416_reward_63.056.pth:  16% 6.34M/39.3M [00:02\u003c00:09, 3.63MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Download file checkpoint_p0/checkpoint_000538763_4413546496.pth:  92% 36.2M/39.3M [00:09\u003c00:00, 4.72MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Download file checkpoint_p0/checkpoint_000539850_4422451200.pth: 100% 39.2M/39.3M [00:10\u003c00:00, 4.36MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/best_000466273_3819708416_reward_63.056.pth:  25% 9.75M/39.3M [00:03\u003c00:08, 3.60MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/best_000466273_3819708416_reward_63.056.pth:  44% 17.5M/39.3M [00:04\u003c00:04, 5.37MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/best_000466273_3819708416_reward_63.056.pth:  67% 26.3M/39.3M [00:05\u003c00:02, 6.76MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/best_000466273_3819708416_reward_63.056.pth:  90% 35.6M/39.3M [00:06\u003c00:00, 7.76MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/checkpoint_000538763_4413546496.pth:   0% 1.00k/39.3M [00:00\u003c?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/checkpoint_000538763_4413546496.pth:  12% 4.84M/39.3M [00:01\u003c00:07, 5.07MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/checkpoint_000538763_4413546496.pth:  36% 14.2M/39.3M [00:02\u003c00:03, 7.84MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/checkpoint_000538763_4413546496.pth:  59% 23.3M/39.3M [00:03\u003c00:01, 8.62MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/checkpoint_000538763_4413546496.pth:  83% 32.5M/39.3M [00:04\u003c00:00, 9.00MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/checkpoint_000539850_4422451200.pth:   0% 1.00k/39.3M [00:00\u003c?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Clean file .summary/0/events.out.tfevents.1666554178.r12i0n7: 100% 8.77M/8.77M [00:14\u003c00:00, 4.12MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Download file checkpoint_p0/best_000466273_3819708416_reward_63.056.pth: 100% 39.3M/39.3M [00:19\u003c00:00, 4.75MB/s]\n","Download file replay.mp4: 100% 4.07M/4.07M [00:18\u003c00:00, 1.70MB/s]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/checkpoint_000539850_4422451200.pth:   5% 1.88M/39.3M [00:01\u003c00:19, 1.96MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/checkpoint_000539850_4422451200.pth:  28% 11.0M/39.3M [00:02\u003c00:04, 6.43MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/checkpoint_000539850_4422451200.pth:  52% 20.3M/39.3M [00:03\u003c00:02, 7.96MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","Download file checkpoint_p0/best_000466273_3819708416_reward_63.056.pth: 100% 39.3M/39.3M [00:24\u003c00:00, 1.71MB/s]\n","\n","Download file replay.mp4: 100% 4.07M/4.07M [00:23\u003c00:00, 139kB/s] \u001b[A\n","Download file replay.mp4: 100% 4.07M/4.07M [00:23\u003c00:00, 185kB/s]\n","\n","\n","Download file .summary/0/events.out.tfevents.1666554178.r12i0n7: 100% 8.77M/8.77M [00:22\u003c00:00, 289kB/s] \u001b[A\u001b[A\n","\n","Download file .summary/0/events.out.tfevents.1666554178.r12i0n7: 100% 8.77M/8.77M [00:22\u003c00:00, 415kB/s]\n","\n","\n","\n","Download file checkpoint_p0/checkpoint_000538763_4413546496.pth: 100% 39.3M/39.3M [00:22\u003c00:00, 909kB/s] \u001b[A\u001b[A\u001b[A\n","\n","\n","Download file checkpoint_p0/checkpoint_000538763_4413546496.pth: 100% 39.3M/39.3M [00:22\u003c00:00, 1.87MB/s]\n","\n","\n","\n","\n","Download file checkpoint_p0/checkpoint_000539850_4422451200.pth: 100% 39.3M/39.3M [00:22\u003c00:00, 1.87MB/s]\n","\n","\n","\n","\n","\n","Clean file replay.mp4: 100% 4.07M/4.07M [00:20\u003c00:00, 213kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Clean file replay.mp4: 100% 4.07M/4.07M [00:20\u003c00:00, 213kB/s]\n","\n","\n","\n","\n","\n","\n","Clean file .summary/0/events.out.tfevents.1666554178.r12i0n7: 100% 8.77M/8.77M [00:19\u003c00:00, 424kB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Clean file .summary/0/events.out.tfevents.1666554178.r12i0n7: 100% 8.77M/8.77M [00:19\u003c00:00, 483kB/s]\n","\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/best_000466273_3819708416_reward_63.056.pth: 100% 39.3M/39.3M [00:15\u003c00:00, 1.80MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/best_000466273_3819708416_reward_63.056.pth: 100% 39.3M/39.3M [00:15\u003c00:00, 2.74MB/s]\n","\n","\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/checkpoint_000538763_4413546496.pth: 100% 39.3M/39.3M [00:09\u003c00:00, 3.41MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/checkpoint_000538763_4413546496.pth: 100% 39.3M/39.3M [00:09\u003c00:00, 4.57MB/s]\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/checkpoint_000539850_4422451200.pth: 100% 39.3M/39.3M [00:05\u003c00:00, 9.21MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/checkpoint_000539850_4422451200.pth: 100% 39.3M/39.3M [00:05\u003c00:00, 8.23MB/s]\n","\u001b[37m\u001b[1m[2024-01-06 06:39:50,890][16985] The repository edbeeching/doom_health_gathering_supreme_2222 has been cloned to ./train_dir/doom_health_gathering_supreme_2222\u001b[0m\n"]}],"source":["#download the agent from the hub\n","!python -m sample_factory.huggingface.load_from_hub -r edbeeching/doom_health_gathering_supreme_2222 -d ./train_dir"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":702,"status":"ok","timestamp":1704523201177,"user":{"displayName":"Weiming Li","userId":"10689989110268100587"},"user_tz":-480},"id":"Ei0cEcJfYZxy","outputId":"60355a74-8cfe-488e-d2ba-a64a9832f9a9"},"outputs":[{"name":"stdout","output_type":"stream","text":["cfg.json  checkpoint_p0  README.md  replay.mp4\n"]}],"source":["!ls train_dir/doom_health_gathering_supreme_2222"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":167782,"status":"ok","timestamp":1704523371062,"user":{"displayName":"Weiming Li","userId":"10689989110268100587"},"user_tz":-480},"id":"99Yl4KZMYdzi","outputId":"0e4389bf-79e0-43ee-c93e-5c4db15da1db"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[33m[2024-01-06 06:40:02,998][00204] Loading legacy config file train_dir/doom_health_gathering_supreme_2222/cfg.json instead of train_dir/doom_health_gathering_supreme_2222/config.json\u001b[0m\n","\u001b[33m[2024-01-06 06:40:03,000][00204] Loading existing experiment configuration from train_dir/doom_health_gathering_supreme_2222/config.json\u001b[0m\n","\u001b[36m[2024-01-06 06:40:03,002][00204] Overriding arg 'experiment' with value 'doom_health_gathering_supreme_2222' passed from command line\u001b[0m\n","\u001b[36m[2024-01-06 06:40:03,004][00204] Overriding arg 'train_dir' with value 'train_dir' passed from command line\u001b[0m\n","\u001b[36m[2024-01-06 06:40:03,006][00204] Overriding arg 'num_workers' with value 1 passed from command line\u001b[0m\n","\u001b[36m[2024-01-06 06:40:03,008][00204] Adding new argument 'env_gpu_observations'=True that is not in the saved config file!\u001b[0m\n","\u001b[36m[2024-01-06 06:40:03,010][00204] Adding new argument 'no_render'=True that is not in the saved config file!\u001b[0m\n","\u001b[36m[2024-01-06 06:40:03,011][00204] Adding new argument 'save_video'=True that is not in the saved config file!\u001b[0m\n","\u001b[36m[2024-01-06 06:40:03,013][00204] Adding new argument 'video_frames'=1000000000.0 that is not in the saved config file!\u001b[0m\n","\u001b[36m[2024-01-06 06:40:03,014][00204] Adding new argument 'video_name'=None that is not in the saved config file!\u001b[0m\n","\u001b[36m[2024-01-06 06:40:03,016][00204] Adding new argument 'max_num_frames'=1000000000.0 that is not in the saved config file!\u001b[0m\n","\u001b[36m[2024-01-06 06:40:03,017][00204] Adding new argument 'max_num_episodes'=10 that is not in the saved config file!\u001b[0m\n","\u001b[36m[2024-01-06 06:40:03,020][00204] Adding new argument 'push_to_hub'=False that is not in the saved config file!\u001b[0m\n","\u001b[36m[2024-01-06 06:40:03,021][00204] Adding new argument 'hf_repository'=None that is not in the saved config file!\u001b[0m\n","\u001b[36m[2024-01-06 06:40:03,022][00204] Adding new argument 'policy_index'=0 that is not in the saved config file!\u001b[0m\n","\u001b[36m[2024-01-06 06:40:03,024][00204] Adding new argument 'eval_deterministic'=False that is not in the saved config file!\u001b[0m\n","\u001b[36m[2024-01-06 06:40:03,025][00204] Adding new argument 'train_script'='.usr.local.lib.python3.10.dist-packages.colab_kernel_launcher' that is not in the saved config file!\u001b[0m\n","\u001b[36m[2024-01-06 06:40:03,027][00204] Using frameskip 1 and render_action_repeat=4 for evaluation\u001b[0m\n","\u001b[36m[2024-01-06 06:40:03,046][00204] RunningMeanStd input shape: (3, 72, 128)\u001b[0m\n","\u001b[36m[2024-01-06 06:40:03,048][00204] RunningMeanStd input shape: (1,)\u001b[0m\n","\u001b[36m[2024-01-06 06:40:03,063][00204] ConvEncoder: input_channels=3\u001b[0m\n","\u001b[36m[2024-01-06 06:40:03,108][00204] Conv encoder output size: 512\u001b[0m\n","\u001b[36m[2024-01-06 06:40:03,115][00204] Policy head output size: 512\u001b[0m\n","\u001b[33m[2024-01-06 06:40:03,137][00204] Loading state from checkpoint train_dir/doom_health_gathering_supreme_2222/checkpoint_p0/checkpoint_000539850_4422451200.pth...\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:40:07,193][00204] Avg episode rewards: #0: 66.999, true rewards: #0: 21.000\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:40:07,195][00204] Avg episode reward: 66.999, avg true_objective: 21.000\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:40:10,049][00204] Avg episode rewards: #0: 66.999, true rewards: #0: 21.000\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:40:10,051][00204] Avg episode reward: 66.999, avg true_objective: 21.000\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:40:13,258][00204] Avg episode rewards: #0: 65.999, true rewards: #0: 21.000\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:40:13,260][00204] Avg episode reward: 65.999, avg true_objective: 21.000\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:40:16,842][00204] Avg episode rewards: #0: 65.749, true rewards: #0: 21.000\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:40:16,845][00204] Avg episode reward: 65.749, avg true_objective: 21.000\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:40:20,404][00204] Avg episode rewards: #0: 64.799, true rewards: #0: 21.000\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:40:20,406][00204] Avg episode reward: 64.799, avg true_objective: 21.000\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:40:23,106][00204] Avg episode rewards: #0: 63.332, true rewards: #0: 21.000\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:40:23,107][00204] Avg episode reward: 63.332, avg true_objective: 21.000\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:40:25,831][00204] Avg episode rewards: #0: 62.713, true rewards: #0: 21.000\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:40:25,833][00204] Avg episode reward: 62.713, avg true_objective: 21.000\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:40:28,585][00204] Avg episode rewards: #0: 63.249, true rewards: #0: 21.000\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:40:28,587][00204] Avg episode reward: 63.249, avg true_objective: 21.000\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:40:31,946][00204] Avg episode rewards: #0: 63.554, true rewards: #0: 21.000\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:40:31,951][00204] Avg episode reward: 63.554, avg true_objective: 21.000\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:40:34,899][00204] Avg episode rewards: #0: 63.699, true rewards: #0: 21.000\u001b[0m\n","\u001b[37m\u001b[1m[2024-01-06 06:40:34,901][00204] Avg episode reward: 63.699, avg true_objective: 21.000\u001b[0m\n"]}],"source":["env = \"doom_health_gathering_supreme\"\n","cfg = parse_vizdoom_cfg(argv=[f\"--env={env}\", \"--num_workers=1\", \"--save_video\", \"--no_render\", \"--max_num_episodes=10\", \"--experiment=doom_health_gathering_supreme_2222\", \"--train_dir=train_dir\"], evaluation=True)\n","status = enjoy(cfg)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":1894,"status":"ok","timestamp":1704523382016,"user":{"displayName":"Weiming Li","userId":"10689989110268100587"},"user_tz":-480},"id":"WKdlPeEXYfi_"},"outputs":[],"source":["mp4 = open('/content/train_dir/doom_health_gathering_supreme_2222/replay.mp4','rb').read()\n","data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","HTML(\"\"\"\n","\u003cvideo width=640 controls\u003e\n","      \u003csource src=\"%s\" type=\"video/mp4\"\u003e\n","\u003c/video\u003e\n","\"\"\" % data_url)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29321,"status":"ok","timestamp":1704523421299,"user":{"displayName":"Weiming Li","userId":"10689989110268100587"},"user_tz":-480},"id":"XGlVJ6bHY60m","outputId":"1a4e067f-b6ce-4671-cde2-7e9e9bb5fc3c"},"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n","For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n","  warnings.warn(warning_message, FutureWarning)\n","Cloning https://huggingface.co/edbeeching/doom_deathmatch_bots_2222 into local empty directory.\n","Download file checkpoint_p0/best_000270111_2212749312_reward_93.067.pth:   0% 175k/39.5M [00:01\u003c04:01, 171kB/s]\n","Download file replay.mp4:   0% 15.4k/6.94M [00:00\u003c?, ?B/s]\u001b[A\n","\n","Download file checkpoint_p0/checkpoint_000281648_2307260416.pth:   0% 16.5k/39.5M [00:00\u003c?, ?B/s]\u001b[A\u001b[A\n","\n","\n","Download file checkpoint_p0/checkpoint_000282220_2311946240.pth:   0% 31.4k/39.5M [00:00\u003c?, ?B/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Download file .summary/0/events.out.tfevents.1666554187.r13i1n3:   0% 32.0k/9.32M [00:00\u003c?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Download file checkpoint_p0/best_000270111_2212749312_reward_93.067.pth:   8% 3.15M/39.5M [00:02\u003c00:20, 1.90MB/s]\n","\n","\n","Download file checkpoint_p0/checkpoint_000282220_2311946240.pth:   0% 99.4k/39.5M [00:01\u003c09:54, 69.5kB/s]\u001b[A\u001b[A\u001b[A\n","Download file replay.mp4:   2% 148k/6.94M [00:01\u003c00:52, 135kB/s]\u001b[A\n","\n","\n","\n","Download file .summary/0/events.out.tfevents.1666554187.r13i1n3:   1% 118k/9.32M [00:01\u003c01:49, 88.0kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Download file checkpoint_p0/checkpoint_000282220_2311946240.pth:   3% 1.14M/39.5M [00:02\u003c00:59, 673kB/s] \u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Download file checkpoint_p0/best_000270111_2212749312_reward_93.067.pth:  24% 9.40M/39.5M [00:03\u003c00:07, 4.02MB/s]\n","\n","Download file checkpoint_p0/checkpoint_000281648_2307260416.pth:   4% 1.53M/39.5M [00:02\u003c00:43, 908kB/s]\u001b[A\u001b[A\n","Download file replay.mp4:  28% 1.97M/6.94M [00:02\u003c00:04, 1.18MB/s]\u001b[A\n","\n","Download file checkpoint_p0/checkpoint_000281648_2307260416.pth:  16% 6.17M/39.5M [00:03\u003c00:12, 2.71MB/s]\u001b[A\u001b[A\n","Download file replay.mp4:  98% 6.81M/6.94M [00:03\u003c00:00, 2.95MB/s]\u001b[A\n","\n","\n","\n","Download file checkpoint_p0/best_000270111_2212749312_reward_93.067.pth:  36% 14.2M/39.5M [00:04\u003c00:05, 4.43MB/s]\n","\n","\n","Download file checkpoint_p0/checkpoint_000282220_2311946240.pth:  15% 5.74M/39.5M [00:03\u003c00:13, 2.56MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Clean file replay.mp4:   0% 1.00k/6.94M [00:00\u003c?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Clean file replay.mp4:  53% 3.66M/6.94M [00:01\u003c00:00, 3.82MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Download file checkpoint_p0/checkpoint_000282220_2311946240.pth:  25% 9.95M/39.5M [00:04\u003c00:09, 3.29MB/s]\u001b[A\u001b[A\u001b[A\n","\n","Download file checkpoint_p0/best_000270111_2212749312_reward_93.067.pth:  47% 18.5M/39.5M [00:05\u003c00:04, 4.42MB/s]\n","\n","\n","\n","\n","\n","Download file checkpoint_p0/best_000270111_2212749312_reward_93.067.pth:  59% 23.2M/39.5M [00:06\u003c00:03, 4.58MB/s]\n","\n","\n","\n","\n","\n","Clean file .summary/0/events.out.tfevents.1666554187.r13i1n3:  14% 1.31M/9.32M [00:01\u003c00:06, 1.37MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Download file checkpoint_p0/checkpoint_000282220_2311946240.pth:  37% 14.6M/39.5M [00:05\u003c00:06, 3.86MB/s]\u001b[A\u001b[A\u001b[A\n","\n","Download file checkpoint_p0/best_000270111_2212749312_reward_93.067.pth:  70% 27.8M/39.5M [00:07\u003c00:02, 4.67MB/s]\n","\n","\n","Download file checkpoint_p0/checkpoint_000282220_2311946240.pth:  49% 19.3M/39.5M [00:06\u003c00:05, 4.21MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Clean file .summary/0/events.out.tfevents.1666554187.r13i1n3:  64% 5.97M/9.32M [00:02\u003c00:01, 3.42MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Download file checkpoint_p0/best_000270111_2212749312_reward_93.067.pth:  81% 32.0M/39.5M [00:08\u003c00:01, 4.56MB/s]\n","\n","\n","Download file checkpoint_p0/checkpoint_000282220_2311946240.pth:  59% 23.5M/39.5M [00:07\u003c00:03, 4.25MB/s]\u001b[A\u001b[A\u001b[A\n","\n","Download file checkpoint_p0/checkpoint_000281648_2307260416.pth:  61% 23.9M/39.5M [00:07\u003c00:03, 4.29MB/s]\u001b[A\u001b[A\n","\n","Download file checkpoint_p0/checkpoint_000281648_2307260416.pth:  73% 28.8M/39.5M [00:08\u003c00:02, 4.54MB/s]\u001b[A\u001b[A\n","\n","\n","Download file checkpoint_p0/best_000270111_2212749312_reward_93.067.pth:  93% 36.9M/39.5M [00:09\u003c00:00, 4.74MB/s]\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/best_000270111_2212749312_reward_93.067.pth:   0% 1.00k/39.5M [00:00\u003c?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Download file checkpoint_p0/checkpoint_000281648_2307260416.pth:  81% 31.9M/39.5M [00:09\u003c00:01, 4.13MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/best_000270111_2212749312_reward_93.067.pth:   1% 321k/39.5M [00:01\u003c02:05, 327kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Download file checkpoint_p0/checkpoint_000282220_2311946240.pth:  80% 31.5M/39.5M [00:09\u003c00:02, 4.13MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Download file checkpoint_p0/checkpoint_000282220_2311946240.pth:  91% 36.0M/39.5M [00:10\u003c00:00, 4.29MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/best_000270111_2212749312_reward_93.067.pth:  12% 4.75M/39.5M [00:02\u003c00:12, 2.87MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Download file checkpoint_p0/checkpoint_000281648_2307260416.pth:  92% 36.4M/39.5M [00:10\u003c00:00, 4.31MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/best_000270111_2212749312_reward_93.067.pth:  21% 8.19M/39.5M [00:03\u003c00:10, 3.20MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Download file checkpoint_p0/checkpoint_000282220_2311946240.pth: 100% 39.4M/39.5M [00:11\u003c00:00, 4.09MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/best_000270111_2212749312_reward_93.067.pth:  37% 14.7M/39.5M [00:04\u003c00:05, 4.62MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/best_000270111_2212749312_reward_93.067.pth:  59% 23.4M/39.5M [00:05\u003c00:02, 6.26MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/best_000270111_2212749312_reward_93.067.pth:  82% 32.4M/39.5M [00:06\u003c00:01, 7.32MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/checkpoint_000281648_2307260416.pth:   0% 1.00k/39.5M [00:00\u003c?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/checkpoint_000281648_2307260416.pth:   4% 1.63M/39.5M [00:01\u003c00:23, 1.70MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/checkpoint_000281648_2307260416.pth:  27% 10.5M/39.5M [00:02\u003c00:04, 6.17MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/checkpoint_000281648_2307260416.pth:  48% 18.9M/39.5M [00:03\u003c00:02, 7.38MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/checkpoint_000281648_2307260416.pth:  71% 27.9M/39.5M [00:04\u003c00:01, 8.19MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Clean file .summary/0/events.out.tfevents.1666554187.r13i1n3: 100% 9.32M/9.32M [00:14\u003c00:00, 3.42MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Download file checkpoint_p0/best_000270111_2212749312_reward_93.067.pth: 100% 39.5M/39.5M [00:20\u003c00:00, 4.74MB/s]\n","Download file replay.mp4: 100% 6.94M/6.94M [00:18\u003c00:00, 2.95MB/s]\u001b[A\n","\n","\n","\n","\n","Clean file replay.mp4: 100% 6.94M/6.94M [00:15\u003c00:00, 3.82MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/checkpoint_000281648_2307260416.pth:  93% 36.9M/39.5M [00:05\u003c00:00, 8.61MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/checkpoint_000282220_2311946240.pth:   0% 1.00k/39.5M [00:00\u003c?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/checkpoint_000282220_2311946240.pth:  16% 6.22M/39.5M [00:01\u003c00:05, 6.51MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/checkpoint_000282220_2311946240.pth:  39% 15.4M/39.5M [00:02\u003c00:03, 8.34MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","Download file checkpoint_p0/best_000270111_2212749312_reward_93.067.pth: 100% 39.5M/39.5M [00:24\u003c00:00, 1.72MB/s]\n","\n","Download file replay.mp4: 100% 6.94M/6.94M [00:23\u003c00:00, 217kB/s] \u001b[A\n","Download file replay.mp4: 100% 6.94M/6.94M [00:23\u003c00:00, 315kB/s]\n","\n","\n","Download file checkpoint_p0/checkpoint_000281648_2307260416.pth: 100% 39.5M/39.5M [00:23\u003c00:00, 854kB/s] \u001b[A\u001b[A\n","\n","Download file checkpoint_p0/checkpoint_000281648_2307260416.pth: 100% 39.5M/39.5M [00:23\u003c00:00, 1.80MB/s]\n","\n","\n","\n","Download file checkpoint_p0/checkpoint_000282220_2311946240.pth: 100% 39.5M/39.5M [00:23\u003c00:00, 1.80MB/s]\n","\n","\n","\n","\n","Download file .summary/0/events.out.tfevents.1666554187.r13i1n3: 100% 9.32M/9.32M [00:23\u003c00:00, 351kB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Download file .summary/0/events.out.tfevents.1666554187.r13i1n3: 100% 9.32M/9.32M [00:23\u003c00:00, 422kB/s]\n","\n","\n","\n","\n","\n","Clean file replay.mp4: 100% 6.94M/6.94M [00:20\u003c00:00, 310kB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Clean file replay.mp4: 100% 6.94M/6.94M [00:20\u003c00:00, 363kB/s]\n","\n","\n","\n","\n","\n","\n","Clean file .summary/0/events.out.tfevents.1666554187.r13i1n3: 100% 9.32M/9.32M [00:19\u003c00:00, 417kB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Clean file .summary/0/events.out.tfevents.1666554187.r13i1n3: 100% 9.32M/9.32M [00:19\u003c00:00, 513kB/s]\n","\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/best_000270111_2212749312_reward_93.067.pth: 100% 39.5M/39.5M [00:15\u003c00:00, 2.04MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/best_000270111_2212749312_reward_93.067.pth: 100% 39.5M/39.5M [00:15\u003c00:00, 2.76MB/s]\n","\n","\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/checkpoint_000281648_2307260416.pth: 100% 39.5M/39.5M [00:09\u003c00:00, 3.28MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/checkpoint_000281648_2307260416.pth: 100% 39.5M/39.5M [00:09\u003c00:00, 4.59MB/s]\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/checkpoint_000282220_2311946240.pth: 100% 39.5M/39.5M [00:04\u003c00:00, 11.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","Clean file checkpoint_p0/checkpoint_000282220_2311946240.pth: 100% 39.5M/39.5M [00:04\u003c00:00, 10.3MB/s]\n","\u001b[37m\u001b[1m[2024-01-06 06:43:40,540][18056] The repository edbeeching/doom_deathmatch_bots_2222 has been cloned to ./train_dir/doom_deathmatch_bots_2222\u001b[0m\n"]}],"source":["# Download the agent from the hub\n","!python -m sample_factory.huggingface.load_from_hub -r edbeeching/doom_deathmatch_bots_2222 -d ./train_dir"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","output_embedded_package_id":"1jra77TxhdfLcl8ZSlUapw3aiwhEYawLe"},"executionInfo":{"elapsed":145323,"status":"ok","timestamp":1704523574243,"user":{"displayName":"Weiming Li","userId":"10689989110268100587"},"user_tz":-480},"id":"jmXGUkzPY7QP","outputId":"2c279f84-0c44-4781-9bb8-8b67e411175d"},"outputs":[],"source":["\n","from sample_factory.enjoy import enjoy\n","register_vizdoom_components()\n","env = \"doom_deathmatch_bots\"\n","cfg = parse_vizdoom_cfg(argv=[f\"--env={env}\", \"--num_workers=1\", \"--save_video\", \"--no_render\", \"--max_num_episodes=1\", \"--experiment=doom_deathmatch_bots_2222\", \"--train_dir=train_dir\"], evaluation=True)\n","status = enjoy(cfg)\n","mp4 = open('/content/train_dir/doom_deathmatch_bots_2222/replay.mp4','rb').read()\n","data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","HTML(\"\"\"\n","\u003cvideo width=640 controls\u003e\n","      \u003csource src=\"%s\" type=\"video/mp4\"\u003e\n","\u003c/video\u003e\n","\"\"\" % data_url)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPxaVQY1xDl8w8Ow3MaXK0u","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0116ad8bc57245779935a22e1da3ee9f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"017bb4103bfe4210bfb84a7cd36137e8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0325abb2613149348d6bf8ba923628a3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"03ced25426634fd5aec895cdcda495e4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"049e87e3beeb400c918cec1c0f7140ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"06349f4e443948eb844dcf7a73f7c340":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08a50457e93841348dbf7deed7d3eb53":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"09cc61592e9d473fb3420238a939b31e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0fb62a9d990144d8808b049ce7bb25d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_599791b3404b48f0b47a9a0ac1a4696f","IPY_MODEL_b6743af51e964652a3dc3bf0fd54c368","IPY_MODEL_99a2f69a967e4301b6168d44ba3461a5"],"layout":"IPY_MODEL_df7d925571c846a5a1cf153a00bb07f7"}},"103490eb9e9446c2925b1affa5e368fa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5f4a5d5250e49809049eac1056f5ab0","max":34929028,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d3412013352341dd8906de1768cbb7be","value":34929028}},"10eff4a42e4146268b87af59531f50a4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1194c725ca1847639b82c499e1e64d12":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13fab6aa5bcc4ceb8389343c4d0988c8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15468c75f5394a389c8a5819398f0d24":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"15f85ce265ef4fa79864d62e4d0bae81":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17fff2a598a0493d928b4a2f5c301274":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2169c230bdc1413da6dc4fff28c45861":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"21cb75a1ae664984bb43d75503de1db1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26ebee4ea4624ccea50fd3a6e887d417":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2968300e3ee54518bf442bcb4eeac124":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7c3299462654a9f9a8f371d87d8bbf7","placeholder":"​","style":"IPY_MODEL_894a1c9025e94a22b33e078e0275c08b","value":"\n\u003cb\u003ePro Tip:\u003c/b\u003e If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. \u003c/center\u003e"}},"304ffc9cf01b45b5a5e47ffdb2d87999":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33fe360e292546fa837599fc21d550ce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a3c112bc0b04fe988276e6fbfb3cc6c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b702d9f92c7442168f995b4d5fd2dac0","IPY_MODEL_a63a9768f48a4073b69fd6c2719506ff","IPY_MODEL_d85a7acc4e1e4c09aca6d228ae117f33"],"layout":"IPY_MODEL_968858559fde473385375c21e7455fab"}},"3b7efda5fbdb47f98bffd1b35d1b386a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_21cb75a1ae664984bb43d75503de1db1","placeholder":"​","style":"IPY_MODEL_15468c75f5394a389c8a5819398f0d24","value":"best_000001105_4526080_reward_25.856.pth: 100%"}},"3bbc2cd1ae5f4e99af79a8a6419711f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c9a6540c406a4f18ab57528e4497806a","IPY_MODEL_7fcba94dc8834d6d9f8536bb57e33e9e","IPY_MODEL_523eb682efaa46469ec1ebd5dab1af4c"],"layout":"IPY_MODEL_91df7c6007534306a8b931902416e08c"}},"3c0d43157c2a40ae9cd1260ad0a0537c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"3ec4e6d4fed04920bcb5069bf30893f9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"41966217e18d4d608a3fdb7bca8261ba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"423616fe1be04328b5d5c381b9557381":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"462482777b8f434cbd8f221e6142d95f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_26ebee4ea4624ccea50fd3a6e887d417","max":34928614,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d2e256a113e34dfb8638b166c39d6eba","value":34928614}},"476236a6de0f48b49e69f96cec608d8d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_635bf20490da4489bc4430757eb8f31c","placeholder":"​","style":"IPY_MODEL_dede3de81b5f4465add994b39d20b3a8","value":"checkpoint_000001135_4648960.pth: 100%"}},"498e89bb336f42faba7a5c9b659ccf8c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ae996ec9f814ba48ce7a417561c19a7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4be1adda6ba84d3196eadd495573668e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"PasswordModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_9bf91e9c2d4b4527880f9154c74faffa","placeholder":"​","style":"IPY_MODEL_017bb4103bfe4210bfb84a7cd36137e8","value":""}},"4c1eb5384c5c422eac0cbd9498d466d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4ec3f62b72c74faf980f50b37722c577":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5015dc99a7c04e02bed4efe6c9ac8f9f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_17fff2a598a0493d928b4a2f5c301274","placeholder":"​","style":"IPY_MODEL_2169c230bdc1413da6dc4fff28c45861","value":" 34.9M/34.9M [00:07\u0026lt;00:00, 4.33MB/s]"}},"5034302a3e654167b6000750769741ec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"523eb682efaa46469ec1ebd5dab1af4c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_da2582ebf7cd44c4bd2609b410b28d3c","placeholder":"​","style":"IPY_MODEL_049e87e3beeb400c918cec1c0f7140ab","value":" 702k/702k [00:01\u0026lt;00:00, 130kB/s]"}},"599791b3404b48f0b47a9a0ac1a4696f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2146fe6b94b4aa8be61b3d05418ff53","placeholder":"​","style":"IPY_MODEL_cd24d05eeb1f429ba655aba97b0f29ab","value":"replay.mp4: 100%"}},"5d3b1b15caef4da7ab29d620a1dc09b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_adbbc9dac4c1490d91ed798c34e1a6d3","placeholder":"​","style":"IPY_MODEL_3ec4e6d4fed04920bcb5069bf30893f9","value":" 34.9M/34.9M [00:02\u0026lt;00:00, 36.0MB/s]"}},"61a57ab4f376426a9b7798098eb59699":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_304ffc9cf01b45b5a5e47ffdb2d87999","placeholder":"​","style":"IPY_MODEL_8d148c4cd22c407e9a47609b95bf0d39","value":"Your token has been saved to /root/.cache/huggingface/token"}},"635bf20490da4489bc4430757eb8f31c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"657151c29bd743f4a60547d4b0f91ffa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6774f7ed90034d209b79cc6c2520f198":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7129cba74b494066b60764bfcb49b83c","placeholder":"​","style":"IPY_MODEL_d938d62074fb46769a2fe0d292f295ad","value":"checkpoint_000001222_5005312.pth: 100%"}},"695017806acf4c1585c04b271225b765":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3b7efda5fbdb47f98bffd1b35d1b386a","IPY_MODEL_462482777b8f434cbd8f221e6142d95f","IPY_MODEL_5015dc99a7c04e02bed4efe6c9ac8f9f"],"layout":"IPY_MODEL_cbda4d4ded3a43b7b6c0860c4fe6dbf6"}},"6eb7517648c643de953db4db468e7b0e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7129cba74b494066b60764bfcb49b83c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e9b1d6598a54165924dffd19162adb2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6774f7ed90034d209b79cc6c2520f198","IPY_MODEL_103490eb9e9446c2925b1affa5e368fa","IPY_MODEL_5d3b1b15caef4da7ab29d620a1dc09b3"],"layout":"IPY_MODEL_b63e90756dfd49a3ad4254adb8bf51db"}},"7fcba94dc8834d6d9f8536bb57e33e9e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0116ad8bc57245779935a22e1da3ee9f","max":702292,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b938deb329184ce1a890a21224d3e741","value":702292}},"7fcd60d1e342460ba38675c5faae09ea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_498e89bb336f42faba7a5c9b659ccf8c","placeholder":"​","style":"IPY_MODEL_d21081cf59084cd4a58333372eac3ccf","value":" 34.9M/34.9M [00:06\u0026lt;00:00, 15.4MB/s]"}},"894a1c9025e94a22b33e078e0275c08b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8d148c4cd22c407e9a47609b95bf0d39":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8da36c8cde534b5f8eb3461e78ec7ea5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91df7c6007534306a8b931902416e08c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95ce5abb4b164298bea20f74b272fce8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_33fe360e292546fa837599fc21d550ce","max":34929028,"min":0,"orientation":"horizontal","style":"IPY_MODEL_af2ac7157f58429595729a98e646c055","value":34929028}},"968858559fde473385375c21e7455fab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9857adaa066346b3b201b0374e8c59c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9923793b2a044ac985b6a7d2f3fad172":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"99a2f69a967e4301b6168d44ba3461a5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_10eff4a42e4146268b87af59531f50a4","placeholder":"​","style":"IPY_MODEL_06349f4e443948eb844dcf7a73f7c340","value":" 21.7M/21.7M [00:04\u0026lt;00:00, 11.0MB/s]"}},"9bf91e9c2d4b4527880f9154c74faffa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9dcadc46a9f34d8c9b67472e1aac4f1e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_476236a6de0f48b49e69f96cec608d8d","IPY_MODEL_95ce5abb4b164298bea20f74b272fce8","IPY_MODEL_7fcd60d1e342460ba38675c5faae09ea"],"layout":"IPY_MODEL_d95bdc6192014aa483ec430b63815598"}},"9f8ffe8a86724a9a9e1dd3b60eebcde3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_13fab6aa5bcc4ceb8389343c4d0988c8","placeholder":"​","style":"IPY_MODEL_e00c252c04ce44c3a316006ba0d844d4","value":"Your token has been saved in your configured git credential helpers (store)."}},"a61e1e68ebb24629bf1cf9eda2083d98":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ae996ec9f814ba48ce7a417561c19a7","placeholder":"​","style":"IPY_MODEL_edba3aa51ee345daad61fe18a2f6b279","value":"Connecting..."}},"a63a9768f48a4073b69fd6c2719506ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8da36c8cde534b5f8eb3461e78ec7ea5","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ee2eb6a53284423595791af70649b974","value":3}},"adbbc9dac4c1490d91ed798c34e1a6d3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af2ac7157f58429595729a98e646c055":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b63e90756dfd49a3ad4254adb8bf51db":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6743af51e964652a3dc3bf0fd54c368":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ec3f62b72c74faf980f50b37722c577","max":21681341,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6eb7517648c643de953db4db468e7b0e","value":21681341}},"b702d9f92c7442168f995b4d5fd2dac0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15f85ce265ef4fa79864d62e4d0bae81","placeholder":"​","style":"IPY_MODEL_9857adaa066346b3b201b0374e8c59c3","value":"Upload 3 LFS files: 100%"}},"b938deb329184ce1a890a21224d3e741":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c0e6206c83324882a41f4d6751383620":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_657151c29bd743f4a60547d4b0f91ffa","placeholder":"​","style":"IPY_MODEL_9923793b2a044ac985b6a7d2f3fad172","value":"\u003ccenter\u003e \u003cimg\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'\u003e \u003cbr\u003e Copy a token from \u003ca\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\"\u003eyour Hugging Face\ntokens page\u003c/a\u003e and paste it below. \u003cbr\u003e Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. \u003c/center\u003e"}},"c2146fe6b94b4aa8be61b3d05418ff53":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c323618c430e4054a784baa3a756bfd0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"CheckboxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_09cc61592e9d473fb3420238a939b31e","style":"IPY_MODEL_0325abb2613149348d6bf8ba923628a3","value":true}},"c9a6540c406a4f18ab57528e4497806a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_41966217e18d4d608a3fdb7bca8261ba","placeholder":"​","style":"IPY_MODEL_1194c725ca1847639b82c499e1e64d12","value":"events.out.tfevents.1704520964.5f74293c5f3a: 100%"}},"c9b18df74d194e4694f2f9fcafcb18e0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbda4d4ded3a43b7b6c0860c4fe6dbf6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd24d05eeb1f429ba655aba97b0f29ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d21081cf59084cd4a58333372eac3ccf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2142664adae4a159e6375139ce300b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2e256a113e34dfb8638b166c39d6eba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d3412013352341dd8906de1768cbb7be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d85a7acc4e1e4c09aca6d228ae117f33":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9b18df74d194e4694f2f9fcafcb18e0","placeholder":"​","style":"IPY_MODEL_423616fe1be04328b5d5c381b9557381","value":" 3/3 [00:07\u0026lt;00:00,  7.83s/it]"}},"d938d62074fb46769a2fe0d292f295ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d95bdc6192014aa483ec430b63815598":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da2582ebf7cd44c4bd2609b410b28d3c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dede3de81b5f4465add994b39d20b3a8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df7d925571c846a5a1cf153a00bb07f7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e00c252c04ce44c3a316006ba0d844d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e091c5700c48442ca439f71b9847ec77":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e59919af366140dab14d2d2181b9660d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e091c5700c48442ca439f71b9847ec77","placeholder":"​","style":"IPY_MODEL_d2142664adae4a159e6375139ce300b6","value":"Token is valid (permission: write)."}},"e5f4a5d5250e49809049eac1056f5ab0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6f3703816ef4ecea3cc9e93b2a9dc15":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_03ced25426634fd5aec895cdcda495e4","style":"IPY_MODEL_3c0d43157c2a40ae9cd1260ad0a0537c","tooltip":""}},"e7c3299462654a9f9a8f371d87d8bbf7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edba3aa51ee345daad61fe18a2f6b279":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ee2eb6a53284423595791af70649b974":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f759c41120ad42a7b918b357bff0ba93":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_e59919af366140dab14d2d2181b9660d","IPY_MODEL_9f8ffe8a86724a9a9e1dd3b60eebcde3","IPY_MODEL_61a57ab4f376426a9b7798098eb59699","IPY_MODEL_fbb6c1f587d3492ab770cb25c4cba9fb"],"layout":"IPY_MODEL_08a50457e93841348dbf7deed7d3eb53"}},"fbb6c1f587d3492ab770cb25c4cba9fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5034302a3e654167b6000750769741ec","placeholder":"​","style":"IPY_MODEL_4c1eb5384c5c422eac0cbd9498d466d5","value":"Login successful"}}}}},"nbformat":4,"nbformat_minor":0}